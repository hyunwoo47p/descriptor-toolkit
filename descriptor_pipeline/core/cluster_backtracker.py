"""
Cluster Backtracking Module - surviving_descriptors_clusters.json ìƒì„±

Pass 4 â†’ 3 â†’ 2 â†’ 1 ìˆœì„œë¡œ ì—­ì¶”ì í•˜ë©´ì„œ ê° surviving descriptorì˜
ëª¨ë“  í´ëŸ¬ìŠ¤í„° ë©¤ë²„ë“¤ì„ ìž¬ê·€ì ìœ¼ë¡œ ì°¾ì•„ëƒ…ë‹ˆë‹¤.

Author: Memory-Safe Cluster Tracker
"""

import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Set, Optional
from collections import defaultdict


class ClusterBacktracker:
    """
    ì—­ë°©í–¥ í´ëŸ¬ìŠ¤í„° ì¶”ì ê¸°
    
    ìµœì¢… surviving descriptorsì—ì„œ ì‹œìž‘í•˜ì—¬ Pass 4 â†’ 3 â†’ 2 â†’ 1 ìˆœì„œë¡œ
    ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ë©° ê° descriptorì™€ í´ëŸ¬ìŠ¤í„°ë¡œ ë¬¶ì˜€ë˜ ëª¨ë“  ë©¤ë²„ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
    
    Example:
        - Aê°€ ìµœì¢… ìƒì¡´
        - Pass 3: Aê°€ ëŒ€í‘œ, Bê°€ ì œê±° (A-B í´ëŸ¬ìŠ¤í„°)
        - Pass 2: Bê°€ ëŒ€í‘œ, Cê°€ ì œê±° (B-C í´ëŸ¬ìŠ¤í„°)
        â†’ Aì˜ all_cluster_members = {A, B, C}
    """
    
    def __init__(self, output_dir: Path, verbose: bool = True):
        """
        Args:
            output_dir: checkpoint íŒŒì¼ë“¤ì´ ìžˆëŠ” ë””ë ‰í† ë¦¬
            verbose: ë¡œê¹… ì¶œë ¥ ì—¬ë¶€
        """
        self.output_dir = Path(output_dir)
        self.verbose = verbose
        
        # Checkpoint íŒŒì¼ ê²½ë¡œ
        self.checkpoint_files = {
            'pass1': self.output_dir / 'pass1_variance_filtering.json',
            'pass2': self.output_dir / 'pass2_spearman.json',
            'pass3': self.output_dir / 'pass3_vif.json',
            'pass4': self.output_dir / 'pass4_nonlinear.json',
        }
        
        # ë¡œë“œëœ checkpoint ë°ì´í„°
        self.checkpoints = {}
        
    def _log(self, msg: str):
        """ë¡œê¹…"""
        if self.verbose:
            print(msg)
    
    def load_checkpoints(self):
        """ëª¨ë“  checkpoint íŒŒì¼ ë¡œë“œ"""
        self._log("\nðŸ“‚ Loading checkpoint files...")
        
        for pass_name, file_path in self.checkpoint_files.items():
            if file_path.exists():
                with open(file_path, 'r') as f:
                    self.checkpoints[pass_name] = json.load(f)
                self._log(f"  âœ“ {pass_name}: {file_path.name}")
            else:
                self._log(f"  âš  {pass_name}: Not found - {file_path.name}")
                self.checkpoints[pass_name] = None
    
    def _extract_cluster_info(self, pass_name: str) -> Dict[str, Set[str]]:
        """
        íŠ¹ì • Passì˜ í´ëŸ¬ìŠ¤í„° ì •ë³´ ì¶”ì¶œ
        
        Args:
            pass_name: 'pass2', 'pass3', 'pass4'
        
        Returns:
            Dict[representative, Set[all_members]]
            ì˜ˆ: {'A': {'A', 'B', 'C'}, 'D': {'D', 'E'}}
        """
        checkpoint = self.checkpoints.get(pass_name)
        if checkpoint is None:
            return {}
        
        cluster_map = {}
        
        # Pass 1ì€ í´ëŸ¬ìŠ¤í„° ì •ë³´ê°€ ì—†ìŒ (variance filteringë§Œ)
        if pass_name == 'pass1':
            return {}
        
        # Pass 2, 3, 4ëŠ” í´ëŸ¬ìŠ¤í„° ì •ë³´ ìžˆìŒ
        if 'clusters' in checkpoint:
            for cluster in checkpoint['clusters']:
                representative = cluster.get('representative')
                members = set(cluster.get('members', []))
                
                if representative and members:
                    cluster_map[representative] = members
        
        # representatives ë”•ì…”ë„ˆë¦¬ì—ì„œë„ ì •ë³´ ì¶”ì¶œ
        if 'representatives' in checkpoint:
            for rep, cluster_info in checkpoint['representatives'].items():
                members = set(cluster_info.get('members', []))
                if members:
                    cluster_map[rep] = members
        
        return cluster_map
    
    def backtrack_clusters(self, surviving_descriptors: List[str]) -> Dict[str, Dict]:
        """
        ê° surviving descriptorì˜ ì „ì²´ í´ëŸ¬ìŠ¤í„° ë©¤ë²„ ì—­ì¶”ì 
        
        Args:
            surviving_descriptors: ìµœì¢… ìƒì¡´í•œ descriptors ë¦¬ìŠ¤íŠ¸
        
        Returns:
            Dict[descriptor, cluster_info]
            cluster_info = {
                'all_cluster_members': Set[str],
                'alternative_descriptors': Set[str],
                'removal_history': Dict[pass, List[removed]]
            }
        """
        self._log(f"\nðŸ” Backtracking clusters for {len(surviving_descriptors)} descriptors...")
        
        results = {}
        
        for descriptor in surviving_descriptors:
            cluster_info = self._backtrack_single_descriptor(descriptor)
            results[descriptor] = cluster_info
        
        return results
    
    def _backtrack_single_descriptor(self, descriptor: str) -> Dict:
        """
        ë‹¨ì¼ descriptorì˜ í´ëŸ¬ìŠ¤í„° ì—­ì¶”ì 
        
        ìž¬ê·€ì ìœ¼ë¡œ Pass 4 â†’ 3 â†’ 2 â†’ 1 ìˆœì„œë¡œ ì¶”ì 
        """
        # ì¶”ì í•  descriptors (BFS ë°©ì‹)
        tracked = {descriptor}
        all_members = {descriptor}
        removal_history = {}
        
        # Pass ìˆœì„œ (ì—­ìˆœ)
        passes = ['pass4', 'pass3', 'pass2', 'pass1']
        
        for pass_name in passes:
            # ì´ë²ˆ passì˜ í´ëŸ¬ìŠ¤í„° ë§µ
            cluster_map = self._extract_cluster_info(pass_name)
            
            if not cluster_map:
                continue
            
            # í˜„ìž¬ tracked descriptorsê°€ ëŒ€í‘œì¸ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
            new_members = set()
            removed_in_this_pass = []
            
            for tracked_desc in list(tracked):
                if tracked_desc in cluster_map:
                    # ì´ descriptorê°€ ëŒ€í‘œì¸ í´ëŸ¬ìŠ¤í„°ì˜ ëª¨ë“  ë©¤ë²„
                    cluster_members = cluster_map[tracked_desc]
                    new_members.update(cluster_members)
                    
                    # ì œê±°ëœ ë©¤ë²„ (ëŒ€í‘œ ì œì™¸)
                    removed = cluster_members - {tracked_desc}
                    removed_in_this_pass.extend(removed)
            
            # ìƒˆë¡œìš´ ë©¤ë²„ë“¤ì„ ë‹¤ìŒ passì—ì„œë„ ì¶”ì 
            if new_members:
                all_members.update(new_members)
                tracked.update(new_members)
            
            # ì´ë²ˆ passì—ì„œ ì œê±°ëœ ë©¤ë²„ ê¸°ë¡
            if removed_in_this_pass:
                removal_history[pass_name] = sorted(removed_in_this_pass)
        
        # Alternative descriptors (ë³¸ì¸ ì œì™¸)
        alternative = all_members - {descriptor}
        
        return {
            'all_cluster_members': sorted(all_members),
            'alternative_descriptors': sorted(alternative),
            'removal_history': removal_history,
            'total_alternatives': len(alternative)
        }
    
    def build_cluster_structure(self, final_descriptors_file: Optional[str] = None) -> Dict:
        """
        surviving_descriptors_clusters.json êµ¬ì¡° ìƒì„±
        
        Args:
            final_descriptors_file: final_descriptors.txt íŒŒì¼ ê²½ë¡œ
                                   (Noneì´ë©´ output_dir/final_descriptors.txt)
        
        Returns:
            ì „ì²´ í´ëŸ¬ìŠ¤í„° êµ¬ì¡° ë”•ì…”ë„ˆë¦¬
        """
        self._log("\n" + "="*70)
        self._log("Building Surviving Descriptors Cluster Structure")
        self._log("="*70)
        
        # Checkpoint íŒŒì¼ ë¡œë“œ
        self.load_checkpoints()
        
        # ìµœì¢… descriptors ë¡œë“œ
        if final_descriptors_file is None:
            final_descriptors_file = self.output_dir / 'final_descriptors.txt'
        else:
            final_descriptors_file = Path(final_descriptors_file)
        
        if not final_descriptors_file.exists():
            raise FileNotFoundError(f"Final descriptors file not found: {final_descriptors_file}")
        
        with open(final_descriptors_file, 'r') as f:
            surviving_descriptors = [line.strip() for line in f if line.strip()]
        
        self._log(f"\nðŸ“Š Total surviving descriptors: {len(surviving_descriptors)}")
        
        # í´ëŸ¬ìŠ¤í„° ì—­ì¶”ì 
        cluster_results = self.backtrack_clusters(surviving_descriptors)
        
        # í†µê³„ ê³„ì‚°
        stats = self._calculate_statistics(cluster_results)
        
        # ìµœì¢… êµ¬ì¡° ìƒì„±
        structure = {
            'metadata': {
                'description': f'Cluster structure for {len(surviving_descriptors)} surviving descriptors with full backtracking',
                'total_descriptors': len(surviving_descriptors),
                'descriptors_with_alternatives': sum(1 for info in cluster_results.values() if info['total_alternatives'] > 0),
                'standalone_descriptors': sum(1 for info in cluster_results.values() if info['total_alternatives'] == 0),
                'total_alternative_descriptors': sum(info['total_alternatives'] for info in cluster_results.values()),
            },
            'statistics': stats,
            'descriptors': {}
        }
        
        # ê° descriptor ì •ë³´ ì¶”ê°€
        for descriptor, info in cluster_results.items():
            structure['descriptors'][descriptor] = {
                'cluster_size': len(info['all_cluster_members']),
                'is_representative': True,  # ìµœì¢… ìƒì¡´ìžëŠ” ëª¨ë‘ ëŒ€í‘œ
                'alternative_descriptors': info['alternative_descriptors'],
                'all_cluster_members': info['all_cluster_members'],
                'removal_history': info['removal_history'],
                'total_alternatives': info['total_alternatives']
            }
        
        self._log("\n" + "="*70)
        self._log("Cluster Structure Built Successfully!")
        self._log("="*70)
        self._log(f"Total descriptors: {structure['metadata']['total_descriptors']}")
        self._log(f"With alternatives: {structure['metadata']['descriptors_with_alternatives']}")
        self._log(f"Standalone: {structure['metadata']['standalone_descriptors']}")
        self._log(f"Total alternatives: {structure['metadata']['total_alternative_descriptors']}")
        
        return structure
    
    def _calculate_statistics(self, cluster_results: Dict) -> Dict:
        """í´ëŸ¬ìŠ¤í„° í†µê³„ ê³„ì‚°"""
        cluster_sizes = [len(info['all_cluster_members']) for info in cluster_results.values()]
        
        # í¬ê¸°ë³„ ë¶„í¬
        size_distribution = defaultdict(int)
        for size in cluster_sizes:
            size_distribution[size] += 1
        
        return {
            'cluster_size_mean': float(np.mean(cluster_sizes)) if cluster_sizes else 0,
            'cluster_size_median': float(np.median(cluster_sizes)) if cluster_sizes else 0,
            'cluster_size_min': int(np.min(cluster_sizes)) if cluster_sizes else 0,
            'cluster_size_max': int(np.max(cluster_sizes)) if cluster_sizes else 0,
            'cluster_size_std': float(np.std(cluster_sizes)) if cluster_sizes else 0,
            'size_distribution': {str(k): v for k, v in sorted(size_distribution.items())}
        }
    
    def save_to_json(self, structure: Dict, output_file: Optional[str] = None):
        """JSON íŒŒì¼ë¡œ ì €ìž¥"""
        if output_file is None:
            output_file = self.output_dir / 'surviving_descriptors_clusters.json'
        else:
            output_file = Path(output_file)
        
        with open(output_file, 'w') as f:
            json.dump(structure, f, indent=2)
        
        self._log(f"\nðŸ’¾ Saved to: {output_file}")
        self._log(f"   File size: {output_file.stat().st_size / 1024:.1f} KB")


def create_cluster_structure(output_dir: str, 
                            final_descriptors_file: Optional[str] = None,
                            output_file: Optional[str] = None,
                            verbose: bool = True) -> Dict:
    """
    surviving_descriptors_clusters.json ìƒì„± (íŽ¸ì˜ í•¨ìˆ˜)
    
    Args:
        output_dir: checkpoint íŒŒì¼ë“¤ì´ ìžˆëŠ” ë””ë ‰í† ë¦¬
        final_descriptors_file: final_descriptors.txt íŒŒì¼ ê²½ë¡œ
        output_file: ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ
        verbose: ë¡œê¹… ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        í´ëŸ¬ìŠ¤í„° êµ¬ì¡° ë”•ì…”ë„ˆë¦¬
    
    Example:
        >>> structure = create_cluster_structure(
        ...     output_dir='output/results',
        ...     verbose=True
        ... )
    """
    backtracker = ClusterBacktracker(output_dir, verbose)
    structure = backtracker.build_cluster_structure(final_descriptors_file)
    backtracker.save_to_json(structure, output_file)
    
    return structure


# ============================================================================
# CLI Interface
# ============================================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Generate surviving_descriptors_clusters.json with full backtracking"
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        required=True,
        help='Directory containing checkpoint files'
    )
    parser.add_argument(
        '--final-descriptors',
        type=str,
        default=None,
        help='Path to final_descriptors.txt (default: output-dir/final_descriptors.txt)'
    )
    parser.add_argument(
        '--output-file',
        type=str,
        default=None,
        help='Output JSON file path (default: output-dir/surviving_descriptors_clusters.json)'
    )
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='Suppress verbose output'
    )
    
    args = parser.parse_args()
    
    structure = create_cluster_structure(
        output_dir=args.output_dir,
        final_descriptors_file=args.final_descriptors,
        output_file=args.output_file,
        verbose=not args.quiet
    )
    
    print(f"\nâœ… Done! Generated {len(structure['descriptors'])} descriptor clusters")
