# Descriptor Pipeline ê°œì„  ë²„ì „ - ì„¤ì¹˜ ë° ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ê°œì„  ë²„ì „ì€ ë‹¤ìŒ 3ê°€ì§€ ì£¼ìš” ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤:

1. **ë©”ëª¨ë¦¬ ê´€ë¦¬ ë¬¸ì œ**: GPU ë©”ëª¨ë¦¬ ì„¤ì •ì´ ëˆ„ë½ë˜ì–´ ìˆë˜ ë¬¸ì œ í•´ê²°
2. **ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥**: ì¬ì‹œì‘ ì‹œ ì´ë¯¸ ì™„ë£Œëœ Passë¥¼ ìë™ìœ¼ë¡œ ìŠ¤í‚µí•˜ëŠ” ê¸°ëŠ¥ ì¶”ê°€
3. **ë³€ìˆ˜ ì°¸ì¡° ë¬¸ì œ**: ì½”ë“œ ë‚´ ë³€ìˆ˜ ë¯¸ì§€ì • ë¬¸ì œ ìˆ˜ì •

## ğŸ”§ ì„¤ì¹˜ ë°©ë²•

### 1. ê¸°ì¡´ ì½”ë“œ ë°±ì—…
```bash
cd ~/hyunwoo-proj  # ë˜ëŠ” í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬
cp -r descriptor_pipeline descriptor_pipeline_backup_$(date +%Y%m%d)
```

### 2. ê°œì„ ëœ íŒŒì¼ ì ìš©
```bash
# ì—…ë¡œë“œëœ íŒŒì¼ ì••ì¶• í•´ì œ
unzip descriptor_pipeline_improved.zip

# ì£¼ìš” íŒŒì¼ë“¤ êµì²´
cp descriptor_pipeline_improved/config/settings.py descriptor_pipeline/config/
cp descriptor_pipeline_improved/core/pipeline.py descriptor_pipeline/core/
cp descriptor_pipeline_improved/core/similarity_gpu.py descriptor_pipeline/core/

# ë¬¸ì„œ íŒŒì¼ ë³µì‚¬ (ì„ íƒì‚¬í•­)
cp descriptor_pipeline_improved/IMPROVEMENTS.md descriptor_pipeline/
cp descriptor_pipeline_improved/USAGE_GUIDE.md descriptor_pipeline/
```

### 3. í™•ì¸
```bash
# settings.pyì— max_gpu_memory_gbê°€ ìˆëŠ”ì§€ í™•ì¸
grep "max_gpu_memory_gb" descriptor_pipeline/config/settings.py
# ì¶œë ¥: max_gpu_memory_gb: float = 40.0  # Maximum GPU memory to use (GB)
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‹¤í–‰ (ë³€ê²½ ì—†ìŒ)
```bash
python -u -m descriptor_pipeline.cli.run_pipeline \
  --parquet-glob "/home/ML_data/pubchem/Compound/Filtered_Descriptor/*.parquet" \
  --output-dir "/home/ML_data/pubchem/Compound/Descriptor_clustering/FULL3" \
  --n-metadata 6 \
  --gpu \
  --verbose \
  --batch-rows 50000 \
  --variance-threshold 0.002 \
  --range-mode trimmed \
  --trim-lower 2.5 \
  --trim-upper 97.5 \
  --max-missing-ratio 0.9 \
  --spearman-threshold 0.90 \
  --vif-threshold 10 \
  --nonlinear-threshold 0.7 \
  --w-hsic 0.3 \
  --w-rdc 0.7 \
  --m 8192 \
  --r 5 \
  --hsic-D 8 \
  --rdc-d 12 \
  --rdc-seeds 2 \
  --topk 40 \
  --leiden-resolution 1.0 \
  --n-consensus 10 \
  --random-seed 1557 \
  --checkpoint \
  2>&1 | tee /home/ML_data/pubchem/Compound/Descriptor_clustering/FULL3/output.log
```

**ì¤‘ìš”**: ê¸°ì¡´ ëª…ë ¹ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤! ëª¨ë“  ì¸ìê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.

## ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥

### ìë™ ì¬ê°œ
ì‘ì—…ì´ ì¤‘ë‹¨ëœ í›„ ê°™ì€ ëª…ë ¹ì–´ë¡œ ì¬ì‹¤í–‰í•˜ë©´:

```
âœ“ Pass 0: Sampling already completed (using cached file)
âœ“ Pass 1: Statistics & Variance Filtering already completed (loading from checkpoint)
â†’ Pass 2: Spearman Correlation Filtering (GPU) ... ì—¬ê¸°ì„œë¶€í„° ì¬ê°œ
```

### ì €ì¥ë˜ëŠ” íŒŒì¼ë“¤
```
output_dir/
â”œâ”€â”€ sampled_data.parquet             # Pass0 ìƒ˜í”Œë§ ê²°ê³¼
â”œâ”€â”€ pass1_variance_filtering.json    # Pass1 ì™„ë£Œ ì •ë³´
â”œâ”€â”€ pass1_columns.txt                # Pass1 ê²°ê³¼ ì»¬ëŸ¼ (í…ìŠ¤íŠ¸)
â”œâ”€â”€ pass1_stats.npz                  # Pass1 í†µê³„ (NumPy ì••ì¶•)
â”œâ”€â”€ pass2_spearman.json              # Pass2 ì™„ë£Œ ì •ë³´
â”œâ”€â”€ pass2_columns.txt                # Pass2 ê²°ê³¼ ì»¬ëŸ¼
â”œâ”€â”€ pass2_spearman_matrix.npy        # Spearman ìƒê´€í–‰ë ¬ (ì¬ì‚¬ìš©)
â”œâ”€â”€ pass3_vif.json                   # Pass3 ì™„ë£Œ ì •ë³´
â”œâ”€â”€ pass3_columns.txt                # Pass3 ê²°ê³¼ ì»¬ëŸ¼
â”œâ”€â”€ pass4_nonlinear.json             # Pass4 ì™„ë£Œ ì •ë³´
â”œâ”€â”€ final_descriptors.txt            # ìµœì¢… ê²°ê³¼
â””â”€â”€ output.log                       # ì‹¤í–‰ ë¡œê·¸
```

### ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´
```bash
# ë°©ë²• 1: output ë””ë ‰í† ë¦¬ ì‚­ì œ
rm -rf /home/ML_data/pubchem/Compound/Descriptor_clustering/FULL3

# ë°©ë²• 2: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë§Œ ì‚­ì œ
rm /home/ML_data/pubchem/Compound/Descriptor_clustering/FULL3/pass*.json
rm /home/ML_data/pubchem/Compound/Descriptor_clustering/FULL3/pass*.txt
rm /home/ML_data/pubchem/Compound/Descriptor_clustering/FULL3/pass*.npy
rm /home/ML_data/pubchem/Compound/Descriptor_clustering/FULL3/pass*.npz
```

## ğŸ“Š ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
```bash
# ìƒˆ í„°ë¯¸ë„ì—ì„œ
tail -f /home/ML_data/pubchem/Compound/Descriptor_clustering/FULL3/output.log
```

### ì²´í¬í¬ì¸íŠ¸ ìƒíƒœ í™•ì¸
```bash
# ì–´ë–¤ Passê¹Œì§€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
ls -lh /home/ML_data/pubchem/Compound/Descriptor_clustering/FULL3/pass*.json

# ê° Passë³„ ê²°ê³¼ ì»¬ëŸ¼ ìˆ˜ í™•ì¸
wc -l /home/ML_data/pubchem/Compound/Descriptor_clustering/FULL3/pass*_columns.txt
```

## âš™ï¸ ë©”ëª¨ë¦¬ ì„¤ì • ì¡°ì •

### GPU ë©”ëª¨ë¦¬ í•œë„ ë³€ê²½
RTX 6000 Ada (48GB)ì—ì„œ OOM ë°œìƒ ì‹œ:

```bash
# descriptor_pipeline/config/settings.py í¸ì§‘
vim descriptor_pipeline/config/settings.py

# ë‹¤ìŒ ì¤„ ìˆ˜ì •
max_gpu_memory_gb: float = 35.0  # 40.0 â†’ 35.0ìœ¼ë¡œ ì¤„ì„
```

### ë°°ì¹˜ í¬ê¸° ì¡°ì •
```bash
# ëª…ë ¹ì–´ì—ì„œ --batch-rows ì¡°ì •
--batch-rows 30000  # 50000 â†’ 30000ìœ¼ë¡œ ì¤„ì„
```

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. OOM (Out of Memory) ì—ëŸ¬
```
RuntimeError: CUDA out of memory
```

**í•´ê²° ë°©ë²•:**
```bash
# 1ë‹¨ê³„: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
--batch-rows 30000

# 2ë‹¨ê³„: GPU ë©”ëª¨ë¦¬ í•œë„ ì¤„ì´ê¸°
# settings.pyì—ì„œ max_gpu_memory_gb: float = 35.0

# 3ë‹¨ê³„: GPU ìºì‹œ ì •ë¦¬
python -c "import torch; torch.cuda.empty_cache()"
```

### 2. ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì†ìƒ
```
JSONDecodeError: Expecting value
```

**í•´ê²° ë°©ë²•:**
```bash
# í•´ë‹¹ Passì˜ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ë§Œ ì‚­ì œ
rm /output/dir/pass2*.json
rm /output/dir/pass2*.txt
rm /output/dir/pass2*.npy

# ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ Pass2ë¶€í„° ì¬ê³„ì‚°ë¨
```

### 3. ë³€ìˆ˜ ë¯¸ì§€ì • ì—ëŸ¬
```
AttributeError: 'PipelineConfig' object has no attribute 'max_gpu_memory_gb'
```

**í•´ê²° ë°©ë²•:**
```bash
# settings.pyê°€ ì œëŒ€ë¡œ êµì²´ë˜ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±
# ë‹¤ì‹œ í•œë²ˆ ë³µì‚¬
cp descriptor_pipeline_improved/config/settings.py descriptor_pipeline/config/

# í™•ì¸
grep "max_gpu_memory_gb" descriptor_pipeline/config/settings.py
```

## ğŸ“ˆ ì„±ëŠ¥ ê°œì„  íš¨ê³¼

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **ì´ì „**: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶ˆí™•ì‹¤, ìì£¼ OOM ë°œìƒ
- **ê°œì„ **: 40GB í•œë„ ì„¤ì •, ì•ˆì •ì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬

### ì¬ì‹œì‘ ì‹œê°„
- **ì´ì „**: í•­ìƒ ì²˜ìŒë¶€í„° (12+ ì‹œê°„)
- **ê°œì„ **: 
  - Pass1 ì™„ë£Œ í›„ ì¤‘ë‹¨ â†’ ì¬ì‹œì‘ ì‹œ 11ì‹œê°„ ì ˆì•½
  - Pass2 ì™„ë£Œ í›„ ì¤‘ë‹¨ â†’ ì¬ì‹œì‘ ì‹œ 9ì‹œê°„ ì ˆì•½
  - Pass3 ì™„ë£Œ í›„ ì¤‘ë‹¨ â†’ ì¬ì‹œì‘ ì‹œ 6ì‹œê°„ ì ˆì•½

### ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
- ì²´í¬í¬ì¸íŠ¸ íŒŒì¼: ì•½ 5-10GB ì¶”ê°€
- ëŒ€ì‹  ì¬ê³„ì‚° ì‹œê°„ ëŒ€í­ ì ˆì•½

## âœ… ê²€ì¦ ë°©ë²•

### 1. ì„¤ì¹˜ í™•ì¸
```bash
# Pythonì—ì„œ ì§ì ‘ í™•ì¸
python -c "
from descriptor_pipeline.config.settings import PipelineConfig
config = PipelineConfig(
    parquet_glob='test/*.parquet',
    output_dir='test_output'
)
print(f'max_gpu_memory_gb: {config.max_gpu_memory_gb}')
print('âœ“ ì„¤ì¹˜ ì„±ê³µ!')
"
```

### 2. ì²´í¬í¬ì¸íŠ¸ ë™ì‘ í™•ì¸
```bash
# ì‘ì€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python -u -m descriptor_pipeline.cli.run_pipeline \
  --parquet-glob "/home/ML_data/pubchem/Compound/Filtered_Descriptor/part-000*.parquet" \
  --output-dir "/tmp/test_checkpoint" \
  --n-metadata 6 \
  --gpu \
  --verbose \
  --checkpoint

# Pass1 ì™„ë£Œ í›„ Ctrl+Cë¡œ ì¤‘ë‹¨

# ì¬ì‹œì‘ - Pass1ì´ ìŠ¤í‚µë˜ëŠ”ì§€ í™•ì¸
python -u -m descriptor_pipeline.cli.run_pipeline \
  --parquet-glob "/home/ML_data/pubchem/Compound/Filtered_Descriptor/part-000*.parquet" \
  --output-dir "/tmp/test_checkpoint" \
  --n-metadata 6 \
  --gpu \
  --verbose \
  --checkpoint

# "âœ“ Pass 1: already completed (loading from checkpoint)" ë©”ì‹œì§€ í™•ì¸
```

## ğŸ“ ë¬¸ì˜ ë° ì§€ì›

ë¬¸ì œ ë°œìƒ ì‹œ:
1. ë¡œê·¸ íŒŒì¼ í™•ì¸ (`output.log`)
2. ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ìƒíƒœ í™•ì¸ (`ls -lh output_dir/`)
3. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ (`nvidia-smi`)

## ğŸ”„ ì—…ë°ì´íŠ¸ ì´ë ¥

- **2025-11-04**: 
  - âœ… Configì— `max_gpu_memory_gb` ì¶”ê°€
  - âœ… ì²´í¬í¬ì¸íŠ¸ ì¬ê°œ ê¸°ëŠ¥ ì™„ì„±
  - âœ… GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ê°œì„ 
  - âœ… ì¤‘ê°„ ê²°ê³¼ ì €ì¥/ë¡œë“œ ê¸°ëŠ¥
  - âœ… Passë³„ ìë™ ìŠ¤í‚µ ê¸°ëŠ¥
