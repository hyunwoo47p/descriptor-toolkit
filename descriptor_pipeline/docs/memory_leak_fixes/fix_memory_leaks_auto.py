#!/usr/bin/env python3
"""
ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸
Memory Leak Auto-Fix Script

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. ë°±ì—… ìƒì„±
2. parquet_reader_duckdb.py ìˆ˜ì •
3. similarity_gpu.py ìˆ˜ì •
4. pipeline.py ê²€ì¦ (ìˆ˜ë™ ìˆ˜ì • í•„ìš”)

Usage:
    python fix_memory_leaks_auto.py
"""

import re
import shutil
from pathlib import Path
from datetime import datetime
from typing import List, Tuple


class MemoryLeakFixer:
    """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìë™ ìˆ˜ì • í´ë˜ìŠ¤"""
    
    def __init__(self, base_dir: str = "descriptor_pipeline"):
        self.base_dir = Path(base_dir)
        self.backup_dir = None
        self.fixes_applied = []
        self.manual_fixes_needed = []
    
    def create_backup(self) -> Path:
        """ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = Path(f"descriptor_pipeline_backup_{timestamp}")
        
        print(f"ğŸ“¦ Creating backup: {backup_dir}")
        shutil.copytree(self.base_dir, backup_dir, dirs_exist_ok=True)
        self.backup_dir = backup_dir
        print(f"âœ“ Backup created successfully")
        
        return backup_dir
    
    def fix_parquet_reader_duckdb(self) -> bool:
        """parquet_reader_duckdb.py ìˆ˜ì •"""
        file_path = self.base_dir / "io" / "parquet_reader_duckdb.py"
        
        if not file_path.exists():
            print(f"âœ— File not found: {file_path}")
            return False
        
        print(f"\nğŸ”§ Fixing {file_path.name}...")
        
        content = file_path.read_text(encoding='utf-8')
        original_content = content
        fixes_count = 0
        
        # Fix 1: .values.astype â†’ .values.copy().astype
        pattern1 = r'\.values\.astype\(np\.float64\)'
        replacement1 = r'.values.copy().astype(np.float64)'
        
        new_content, count1 = re.subn(pattern1, replacement1, content)
        if count1 > 0:
            content = new_content
            fixes_count += count1
            print(f"  âœ“ Added .copy() to {count1} locations")
        
        # Fix 2: ì¤‘ë³µ í•¨ìˆ˜ ì œê±° (ë¼ì¸ 226ë¶€í„°)
        lines = content.split('\n')
        second_def_line = -1
        
        for i, line in enumerate(lines):
            if i >= 225 and 'def iter_batches_duckdb' in line:
                second_def_line = i
                break
        
        if second_def_line > 0:
            lines = lines[:second_def_line]
            content = '\n'.join(lines)
            fixes_count += 1
            print(f"  âœ“ Removed duplicate function definition (line {second_def_line + 1})")
        
        if content != original_content:
            file_path.write_text(content, encoding='utf-8')
            self.fixes_applied.append(f"{file_path.name}: {fixes_count} fixes")
            print(f"âœ“ {file_path.name} fixed successfully ({fixes_count} changes)")
            return True
        else:
            print(f"âš  No changes needed for {file_path.name}")
            return False
    
    def fix_similarity_gpu(self) -> bool:
        """similarity_gpu.py ìˆ˜ì •"""
        file_path = self.base_dir / "core" / "similarity_gpu.py"
        
        if not file_path.exists():
            print(f"âœ— File not found: {file_path}")
            return False
        
        print(f"\nğŸ”§ Fixing {file_path.name}...")
        
        content = file_path.read_text(encoding='utf-8')
        original_content = content
        
        # Fix: .cpu().numpy() â†’ .detach().cpu().numpy().copy()
        # ë‹¨, ì´ë¯¸ .detach()ê°€ ìˆëŠ” ê²½ìš°ëŠ” ê±´ë„ˆë›°ê¸°
        pattern = r'(?<!\.detach\(\))\.cpu\(\)\.numpy\(\)'
        replacement = r'.detach().cpu().numpy().copy()'
        
        new_content, count = re.subn(pattern, replacement, content)
        
        if count > 0:
            content = new_content
            file_path.write_text(content, encoding='utf-8')
            self.fixes_applied.append(f"{file_path.name}: {count} fixes")
            print(f"âœ“ {file_path.name} fixed successfully ({count} changes)")
            return True
        else:
            print(f"âš  No changes needed for {file_path.name}")
            return False
    
    def check_pipeline_py(self) -> List[str]:
        """pipeline.py ê²€ì¦ (ìˆ˜ë™ ìˆ˜ì • í•„ìš”)"""
        file_path = self.base_dir / "core" / "pipeline.py"
        
        if not file_path.exists():
            print(f"âœ— File not found: {file_path}")
            return []
        
        print(f"\nğŸ” Checking {file_path.name}...")
        
        content = file_path.read_text(encoding='utf-8')
        lines = content.split('\n')
        
        issues = []
        
        # Check 1: import gc
        if 'import gc' not in content:
            issues.append("Missing 'import gc' statement")
        
        # Check 2: spearman_pass.process í˜¸ì¶œ
        for i, line in enumerate(lines):
            if 'spearman_pass.process' in line:
                # ë‹¤ìŒ ëª‡ ì¤„ í™•ì¸
                context = '\n'.join(lines[i:min(i+5, len(lines))])
                if 'self.graph_builder' in context or 'self.leiden' in context:
                    issues.append(
                        f"Line {i+1}: spearman_pass.process() has incorrect arguments"
                    )
        
        # Check 3: NumPy slicing without .copy()
        view_patterns = [
            r'data\[:,\s*indices_\w+\](?!\.copy\(\))',
            r'G_\w+\[indices_\w+\].*\[indices_\w+\](?!\.copy\(\))',
        ]
        
        for pattern in view_patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                issues.append(
                    f"Line {line_num}: NumPy slicing without .copy() - {match.group()}"
                )
        
        # Check 4: _cleanup_memory ë©”ì„œë“œ
        if '_cleanup_memory' not in content:
            issues.append("Missing _cleanup_memory() method")
        
        if issues:
            print(f"âš  Found {len(issues)} issues requiring manual fixes:")
            for issue in issues:
                print(f"  - {issue}")
            self.manual_fixes_needed.extend(issues)
        else:
            print(f"âœ“ {file_path.name} looks good")
        
        return issues
    
    def print_summary(self):
        """ìˆ˜ì • ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*70)
        print("ìˆ˜ì • ìš”ì•½ (Fix Summary)")
        print("="*70)
        
        if self.backup_dir:
            print(f"\nğŸ“¦ Backup location: {self.backup_dir}")
        
        if self.fixes_applied:
            print(f"\nâœ… Automatically fixed ({len(self.fixes_applied)}):")
            for fix in self.fixes_applied:
                print(f"  - {fix}")
        
        if self.manual_fixes_needed:
            print(f"\nâš ï¸  Manual fixes needed ({len(self.manual_fixes_needed)}):")
            for fix in self.manual_fixes_needed:
                print(f"  - {fix}")
            print("\nğŸ“– Please refer to IMPLEMENTATION_GUIDE.md for details")
        else:
            print("\nâœ“ No manual fixes needed")
        
        print("\n" + "="*70)
        print("Next steps:")
        print("  1. Review changes in modified files")
        print("  2. Apply manual fixes to pipeline.py")
        print("  3. Run tests: python test_memory_fix.py")
        print("  4. If issues occur, restore from backup")
        print("="*70)
    
    def run(self):
        """ì „ì²´ ìˆ˜ì • í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("="*70)
        print("Memory Leak Auto-Fix Script")
        print("="*70)
        
        # 1. ë°±ì—…
        self.create_backup()
        
        # 2. ìë™ ìˆ˜ì •
        try:
            self.fix_parquet_reader_duckdb()
            self.fix_similarity_gpu()
            self.check_pipeline_py()
        except Exception as e:
            print(f"\nâœ— Error during fix: {e}")
            print(f"Backup is available at: {self.backup_dir}")
            return False
        
        # 3. ìš”ì•½
        self.print_summary()
        
        return True


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸
    if not Path("descriptor_pipeline").exists():
        print("âœ— Error: descriptor_pipeline directory not found")
        print("Please run this script from the project root directory")
        sys.exit(1)
    
    # ìˆ˜ì • ì‹¤í–‰
    fixer = MemoryLeakFixer()
    success = fixer.run()
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
