# ë¹ ë¥¸ ìˆ˜ì • ì°¸ì¡° ì‹œíŠ¸ (Quick Fix Reference)

## íŒŒì¼ë³„ ìˆ˜ì •ì‚¬í•­ í•œëˆˆì— ë³´ê¸°

### ğŸ“„ 1. `descriptor_pipeline/io/parquet_reader_duckdb.py`

#### ì‚­ì œí•  ë¶€ë¶„:
```
ë¼ì¸ 226-407: ì „ì²´ ì‚­ì œ (ì¤‘ë³µ í•¨ìˆ˜ ì •ì˜)
```

#### ìˆ˜ì •í•  ë¶€ë¶„ (ì´ 5ê³³):
```python
# ë¼ì¸ 103
X = df_batch[columns].values.astype(np.float64)
# â†’
X = df_batch[columns].values.copy().astype(np.float64)

# ë¼ì¸ 156
X = df_batch[columns].values.astype(np.float64)
# â†’
X = df_batch[columns].values.copy().astype(np.float64)

# ë¼ì¸ 193
X = df_batch[columns].values.astype(np.float64)
# â†’
X = df_batch[columns].values.copy().astype(np.float64)

# ë¼ì¸ 356 (ì¤‘ë³µ í•¨ìˆ˜ ë‚´ - ì‚­ì œ ì˜ˆì •)
# ë¼ì¸ 393 (ì¤‘ë³µ í•¨ìˆ˜ ë‚´ - ì‚­ì œ ì˜ˆì •)
```

---

### ğŸ“„ 2. `descriptor_pipeline/core/pipeline.py`

#### ì¶”ê°€í•  import:
```python
# ë¼ì¸ 6 ê·¼ì²˜ì— ì¶”ê°€
import gc
```

#### ì¶”ê°€í•  ë©”ì„œë“œ:
```python
# ë¼ì¸ 62 ê·¼ì²˜ì— ì¶”ê°€ (run() ë©”ì„œë“œ ì „)
def _cleanup_memory(self):
    """ëª…ì‹œì  ë©”ëª¨ë¦¬ ì •ë¦¬"""
    gc.collect()
    if self.using_gpu:
        import torch
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
```

#### ìˆ˜ì •í•  ë¶€ë¶„ 1: ë¼ì¸ 123-125
```python
# Before
columns_p2, spearman_info, indices_p2 = spearman_pass.process(
    data, columns_p1, G_spearman, self.graph_builder, self.leiden
)

# After
columns_p2, spearman_info, indices_p2 = spearman_pass.process(
    data, columns_p1, G_spearman, stats_p1
)
```

#### ìˆ˜ì •í•  ë¶€ë¶„ 2: ë¼ì¸ 142-143
```python
# Before
data_p2 = data[:, indices_p2]
G_spearman_p2 = G_spearman[indices_p2][:, indices_p2]

# After
data_p2 = data[:, indices_p2].copy()
G_spearman_p2 = G_spearman[indices_p2][:, indices_p2].copy()
stats_p2 = self._filter_stats_by_indices(stats_p1, indices_p2)

# ì¶”ê°€: ì›ë³¸ ì‚­ì œ
del data, G_spearman
self._cleanup_memory()
```

#### ìˆ˜ì •í•  ë¶€ë¶„ 3: ë¼ì¸ 169
```python
# Before
data_p3 = data[:, indices_p3]

# After  
data_p3 = data_p2[:, indices_p3_sub].copy()
stats_p3 = self._filter_stats_by_indices(stats_p1, indices_p3)

# ì¶”ê°€: ì´ì „ ë°ì´í„° ì‚­ì œ
del data_p2, stats_p1, stats_p2
self._cleanup_memory()
```

#### ìˆ˜ì •í•  ë¶€ë¶„ 4: ë¼ì¸ 253-264 (_filter_stats_by_indices)
```python
def _filter_stats_by_indices(self, stats: Dict, indices: np.ndarray) -> Dict:
    """Filter statistics by indices with explicit copy"""
    stats_filtered = {}
    
    for key, value in stats.items():
        if isinstance(value, np.ndarray) and value.ndim >= 1:
            try:
                # FIXED: .copy() ì¶”ê°€
                stats_filtered[key] = value[indices].copy()
            except:
                stats_filtered[key] = value
        elif isinstance(value, list):
            # ì¶”ê°€: ë¦¬ìŠ¤íŠ¸ë„ í•„í„°ë§
            try:
                stats_filtered[key] = [value[i] for i in indices]
            except:
                stats_filtered[key] = value
        else:
            stats_filtered[key] = value
    
    return stats_filtered
```

#### ìˆ˜ì •í•  ë¶€ë¶„ 5: ë¼ì¸ 246-251 (_load_data)
```python
def _load_data(self, parquet_paths: List[str], columns: List[str]) -> np.ndarray:
    """Load data into memory with explicit cleanup"""
    batches = []
    batch_generator = None
    
    try:
        batch_generator = iter_batches(parquet_paths, columns, self.config.batch_rows)
        
        for batch_data, offset in batch_generator:
            batches.append(batch_data.copy())  # .copy() ì¶”ê°€
            del batch_data
    
    finally:
        if batch_generator is not None:
            try:
                batch_generator.close()
            except:
                pass
        gc.collect()
    
    result = np.vstack(batches)
    del batches
    gc.collect()
    
    return result
```

#### ì¶”ê°€í•  cleanup í˜¸ì¶œ (Pass í›„):
```python
# ë¼ì¸ 96 ê·¼ì²˜ (Pass 0 í›„)
self._cleanup_memory()

# ë¼ì¸ 108 ê·¼ì²˜ (Pass 1 í›„)
self._cleanup_memory()

# ë¼ì¸ 134 ê·¼ì²˜ (Pass 2 í›„)
self._cleanup_memory()

# ë¼ì¸ 161 ê·¼ì²˜ (Pass 3 í›„)
self._cleanup_memory()

# ë¼ì¸ 204 ê·¼ì²˜ (Pass 4 í›„)
self._cleanup_memory()
```

---

### ğŸ“„ 3. `descriptor_pipeline/core/similarity_gpu.py`

#### ìˆ˜ì •í•  ë¶€ë¶„ (ì´ 3ê³³):

```python
# ë¼ì¸ 158 ê·¼ì²˜
# Before
G_cpu = G.cpu().numpy()
# After
G_cpu = G.detach().cpu().numpy().copy()

# ë¼ì¸ 390 ê·¼ì²˜
# Before
H_cpu = H.cpu().numpy()
# After
H_cpu = H.detach().cpu().numpy().copy()

# ë¼ì¸ 634 ê·¼ì²˜
# Before
R_cpu = R.cpu().numpy()
# After
R_cpu = R.detach().cpu().numpy().copy()
```

---

## ğŸ” ìˆ˜ì • í™•ì¸ ë°©ë²•

### 1. ë¼ì¸ ë²ˆí˜¸ë¡œ ì°¾ê¸°
```bash
# parquet_reader_duckdb.py
sed -n '103p' descriptor_pipeline/io/parquet_reader_duckdb.py
sed -n '156p' descriptor_pipeline/io/parquet_reader_duckdb.py
sed -n '226,407p' descriptor_pipeline/io/parquet_reader_duckdb.py  # ì‚­ì œí•  ë¶€ë¶„

# pipeline.py
sed -n '123,125p' descriptor_pipeline/core/pipeline.py
sed -n '142,143p' descriptor_pipeline/core/pipeline.py
sed -n '169p' descriptor_pipeline/core/pipeline.py

# similarity_gpu.py
sed -n '158p' descriptor_pipeline/core/similarity_gpu.py
sed -n '390p' descriptor_pipeline/core/similarity_gpu.py
sed -n '634p' descriptor_pipeline/core/similarity_gpu.py
```

### 2. íŒ¨í„´ìœ¼ë¡œ ì°¾ê¸°
```bash
# .values.astype íŒ¨í„´ ì°¾ê¸°
grep -n "\.values\.astype" descriptor_pipeline/io/parquet_reader_duckdb.py

# process í•¨ìˆ˜ í˜¸ì¶œ ì°¾ê¸°
grep -n "spearman_pass.process" descriptor_pipeline/core/pipeline.py

# GPU í…ì„œ ë³€í™˜ ì°¾ê¸°
grep -n "\.cpu()\.numpy()" descriptor_pipeline/core/similarity_gpu.py
```

---

## ğŸ“ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ (ìë™ íŒ¨ì¹˜)

### Option 1: sedë¥¼ ì´ìš©í•œ ìë™ ìˆ˜ì •

```bash
#!/bin/bash
# fix_memory_leaks.sh

# ë°±ì—… ìƒì„±
cp descriptor_pipeline/io/parquet_reader_duckdb.py descriptor_pipeline/io/parquet_reader_duckdb.py.backup
cp descriptor_pipeline/core/pipeline.py descriptor_pipeline/core/pipeline.py.backup
cp descriptor_pipeline/core/similarity_gpu.py descriptor_pipeline/core/similarity_gpu.py.backup

# 1. parquet_reader_duckdb.py ìˆ˜ì •
sed -i 's/\.values\.astype(np\.float64)/.values.copy().astype(np.float64)/g' \
    descriptor_pipeline/io/parquet_reader_duckdb.py

# 2. similarity_gpu.py ìˆ˜ì •
sed -i 's/\.cpu()\.numpy()/.detach().cpu().numpy().copy()/g' \
    descriptor_pipeline/core/similarity_gpu.py

# 3. pipeline.pyëŠ” ìˆ˜ë™ ìˆ˜ì • ê¶Œì¥ (ë³µì¡í•œ ë¡œì§)
echo "pipeline.pyëŠ” ìˆ˜ë™ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."
echo "IMPLEMENTATION_GUIDE.mdë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
```

### Option 2: Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ìˆ˜ì •

```python
# fix_memory_leaks.py
import re
from pathlib import Path

def fix_parquet_reader():
    """parquet_reader_duckdb.py ìˆ˜ì •"""
    file_path = Path("descriptor_pipeline/io/parquet_reader_duckdb.py")
    content = file_path.read_text()
    
    # .copy() ì¶”ê°€
    content = content.replace(
        ".values.astype(np.float64)",
        ".values.copy().astype(np.float64)"
    )
    
    # ì¤‘ë³µ í•¨ìˆ˜ ì œê±° (ë¼ì¸ 226-407)
    lines = content.split('\n')
    # ë¼ì¸ 226 ì°¾ê¸°
    for i, line in enumerate(lines):
        if i >= 225 and 'def iter_batches_duckdb' in line:
            # ë‘ ë²ˆì§¸ ì •ì˜ ì°¾ìŒ
            lines = lines[:i]  # ì´í›„ ì œê±°
            break
    
    content = '\n'.join(lines)
    file_path.write_text(content)
    print(f"âœ“ Fixed: {file_path}")

def fix_similarity_gpu():
    """similarity_gpu.py ìˆ˜ì •"""
    file_path = Path("descriptor_pipeline/core/similarity_gpu.py")
    content = file_path.read_text()
    
    # GPU í…ì„œ ë³€í™˜ ìˆ˜ì •
    content = content.replace(
        ".cpu().numpy()",
        ".detach().cpu().numpy().copy()"
    )
    
    file_path.write_text(content)
    print(f"âœ“ Fixed: {file_path}")

if __name__ == "__main__":
    print("ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìë™ ìˆ˜ì • ì‹œì‘...")
    
    # ë°±ì—…
    import shutil
    import datetime
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    shutil.copytree(
        "descriptor_pipeline",
        f"descriptor_pipeline_backup_{timestamp}",
        dirs_exist_ok=True
    )
    print(f"âœ“ Backup created: descriptor_pipeline_backup_{timestamp}")
    
    # ìˆ˜ì • ì ìš©
    fix_parquet_reader()
    fix_similarity_gpu()
    
    print("\nâš ï¸  pipeline.pyëŠ” ìˆ˜ë™ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    print("IMPLEMENTATION_GUIDE.mdë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.")
```

---

## ğŸ§ª ìˆ˜ì • í›„ í…ŒìŠ¤íŠ¸

```python
# test_memory_fix.py
import tracemalloc
import gc
from descriptor_pipeline.core.pipeline import DescriptorPipeline
from descriptor_pipeline.config.settings import PipelineConfig

def test_memory():
    """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸"""
    tracemalloc.start()
    
    config = PipelineConfig(
        parquet_glob="data/test_*.parquet",
        output_dir="output/test",
        checkpoint=True,
        verbose=True
    )
    
    pipeline = DescriptorPipeline(config)
    
    # ì‹¤í–‰ ì „ ìŠ¤ëƒ…ìƒ·
    gc.collect()
    snapshot1 = tracemalloc.take_snapshot()
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = pipeline.run()
    
    # ì‹¤í–‰ í›„ ìŠ¤ëƒ…ìƒ·
    gc.collect()
    snapshot2 = tracemalloc.take_snapshot()
    
    # ë©”ëª¨ë¦¬ ì¦ê°€ ë¶„ì„
    top_stats = snapshot2.compare_to(snapshot1, 'lineno')
    
    print("\n" + "="*70)
    print("Top 10 Memory Increases:")
    print("="*70)
    for stat in top_stats[:10]:
        print(stat)
    
    tracemalloc.stop()
    
    return results

if __name__ == "__main__":
    results = test_memory()
    print(f"\nâœ… Pipeline completed: {results['final_count']} descriptors")
```

---

## ğŸ“Š ìˆ˜ì • ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### íŒŒì¼ë³„ í™•ì¸
- [ ] `parquet_reader_duckdb.py`
  - [ ] ë¼ì¸ 103: .copy() ì¶”ê°€
  - [ ] ë¼ì¸ 156: .copy() ì¶”ê°€
  - [ ] ë¼ì¸ 193: .copy() ì¶”ê°€
  - [ ] ë¼ì¸ 226-407: ì‚­ì œ
  
- [ ] `pipeline.py`
  - [ ] import gc ì¶”ê°€
  - [ ] _cleanup_memory() ë©”ì„œë“œ ì¶”ê°€
  - [ ] ë¼ì¸ 123-125: í•¨ìˆ˜ í˜¸ì¶œ ìˆ˜ì •
  - [ ] ë¼ì¸ 142-143: .copy() ì¶”ê°€ + ì›ë³¸ ì‚­ì œ
  - [ ] ë¼ì¸ 169: .copy() ì¶”ê°€ + ì›ë³¸ ì‚­ì œ
  - [ ] _filter_stats_by_indices: .copy() ì¶”ê°€
  - [ ] _load_data: ê°œì„ 
  - [ ] 5ê³³ì— _cleanup_memory() í˜¸ì¶œ ì¶”ê°€
  
- [ ] `similarity_gpu.py`
  - [ ] ë¼ì¸ 158: .detach().cpu().numpy().copy()
  - [ ] ë¼ì¸ 390: .detach().cpu().numpy().copy()
  - [ ] ë¼ì¸ 634: .detach().cpu().numpy().copy()

### í…ŒìŠ¤íŠ¸ í™•ì¸
- [ ] ì½”ë“œ ë°±ì—… ì™„ë£Œ
- [ ] ìˆ˜ì • ì ìš© ì™„ë£Œ
- [ ] ì‘ì€ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ì •ìƒ
- [ ] ì „ì²´ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ í†µê³¼

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ
- `MEMORY_LEAK_COMPREHENSIVE_DIAGNOSIS.md`: ìƒì„¸ ì§„ë‹¨
- `IMPLEMENTATION_GUIDE.md`: ë‹¨ê³„ë³„ ê°€ì´ë“œ
- `parquet_reader_duckdb_FIXED.py`: ìˆ˜ì •ëœ íŒŒì¼ ì˜ˆì‹œ
- `pipeline_FIXED.py`: ìˆ˜ì •ëœ íŒŒì¼ ì˜ˆì‹œ
