# ChemDescriptorML (CDML) - 프로그램 구동 방법

## 목차
1. [환경 설정](#1-환경-설정)
2. [기본 사용법](#2-기본-사용법)
3. [Track 1: Descriptor 추출 및 필터링](#3-track-1-descriptor-추출-및-필터링)
4. [Track 2: ML 모델 학습](#4-track-2-ml-모델-학습)
5. [고급 사용법](#5-고급-사용법)
6. [출력 파일 설명](#6-출력-파일-설명)
7. [실행 예시](#7-실행-예시)
8. [문제 해결](#8-문제-해결)

---

## 1. 환경 설정

### 1.1 필수 요구사항
- Python 3.11 이상
- (선택) CUDA 지원 GPU (가속 처리용)

### 1.2 설치 방법

#### 방법 1: pip 설치 (권장)
```bash
# 1. 의존성 먼저 설치
pip install -r requirements.txt

# 2. 패키지 설치
pip install -e .

# 3. (선택) ML 부스팅 모델 설치
pip install xgboost lightgbm
```

#### 방법 2: Conda 환경 사용
```bash
# 환경 생성
conda create -n cdml python=3.11
conda activate cdml

# 의존성 설치
pip install -r requirements.txt

# 패키지 설치
pip install -e .

# (선택) ML 부스팅 모델 설치
pip install xgboost lightgbm
```

### 1.3 주요 의존성 (requirements.txt)
| 패키지 | 버전 | 용도 |
|--------|------|------|
| `numpy` | >=1.24.0 | 수치 연산 |
| `pandas` | >=2.0.0 | 데이터 처리 |
| `pyarrow` | >=12.0.0 | Parquet 파일 I/O |
| `torch` | >=2.0.0 | GPU 가속 |
| `rdkit` | >=2023.3.1 | 분자 처리 |
| `mordred` | >=1.2.0 | Descriptor 계산 |
| `scikit-learn` | >=1.3.0 | ML 알고리즘 |
| `matplotlib` | >=3.7.0 | 시각화 |
| `xgboost` | (선택) | XGBoost 모델 |
| `lightgbm` | (선택) | LightGBM 모델 |

### 1.4 설치 확인
```bash
cdml --version
# 출력: cdml 1.0.0
```

---

## 2. 기본 사용법

### 2.1 명령어 구조
```bash
cdml <명령어> [옵션들]
```

### 2.2 사용 가능한 명령어
| 명령어 | 설명 |
|--------|------|
| `process-all` | 통합 파이프라인 (SMILES → Descriptor → Filtering) |
| `run` | 필터링 파이프라인 실행 (Pass 0-4) |
| `filter` | 개별 필터링 단계 실행 |
| `preprocess` | 데이터 전처리 (XML 변환, 스키마 생성, Descriptor 계산) |
| `train` | ML 모델 학습 |

### 2.3 도움말 확인
```bash
# 전체 도움말
cdml --help

# 특정 명령어 도움말
cdml process-all --help
cdml train --help
```

---

## 3. Track 1: Descriptor 추출 및 필터링

### 3.1 통합 파이프라인 (권장)

가장 간단한 방법으로, 입력 파일에서 descriptor 계산과 필터링까지 한 번에 실행합니다.

```bash
# CSV 입력
cdml process-all \
    --input molecules.csv \
    --output-dir results/ \
    --smiles-col SMILES \
    --id-col CID

# Parquet 입력
cdml process-all \
    --input molecules.parquet \
    --output-dir results/ \
    --smiles-col SMILES

# PubChem XML 입력 (분자량 필터링 포함)
cdml process-all \
    --input compounds.xml.gz \
    --output-dir results/ \
    --filter-property "Molecular Weight" \
    --filter-max 500

# CPU 모드 강제
cdml process-all \
    --input molecules.csv \
    --output-dir results/ \
    --cpu
```

#### `process-all` 옵션 상세

| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--input` | (필수) | 입력 파일 경로 (.csv, .parquet, .xml, .xml.gz) |
| `--output-dir` | (필수) | 출력 디렉토리 |
| `--smiles-col` | `SMILES::Absolute` | SMILES 컬럼명 |
| `--id-col` | `CID` | ID 컬럼명 |
| `--schema` | (자동생성) | 스키마 JSON 파일 경로 |
| `--mol-timeout` | `30` | 분자당 처리 제한 시간 (초) |
| `--cpu` | `False` | CPU 모드 강제 |
| `--gpu-id` | `0` | 사용할 GPU ID |
| `--verbose` | `False` | 상세 출력 |
| `--random-seed` | `42` | 랜덤 시드 |

**필터링 관련 옵션:**
| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--variance-threshold` | `0.01` | 분산 필터링 임계값 |
| `--spearman-threshold` | `0.9` | Spearman 상관계수 임계값 |
| `--vif-threshold` | `10.0` | VIF 임계값 |
| `--nonlinear-threshold` | `0.85` | 비선형 상관 임계값 (HSIC/RDC) |

**XML 전용 옵션:**
| 옵션 | 설명 |
|------|------|
| `--filter-property` | 필터링할 속성명 (예: "H-Bond Donor Count") |
| `--filter-min` | 속성 최소값 |
| `--filter-max` | 속성 최대값 |

### 3.2 필터링만 실행

이미 descriptor가 계산된 parquet 파일이 있는 경우:

```bash
# 전체 필터링 (Pass 0-4)
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/

# 소규모 데이터셋 (샘플 수 < 100)
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/ \
    --min-effective-n 30
```

#### `run` 옵션 상세

| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--parquet-glob` | (필수) | Parquet 파일 glob 패턴 |
| `--output-dir` | (필수) | 출력 디렉토리 |
| `--cpu` | `False` | CPU 모드 강제 |
| `--gpu-id` | `0` | GPU 장치 ID |
| `--no-checkpoint` | `False` | 체크포인트/재시작 비활성화 |
| `--verbose` | `False` | 상세 출력 |
| `--random-seed` | `42` | 랜덤 시드 |
| `--sample-per-file` | (없음) | 파일당 샘플링할 행 수 |
| `--min-effective-n` | `100` | 최소 유효 샘플 수 |
| `--variance-threshold` | `0.01` | 분산 임계값 |
| `--spearman-threshold` | `0.9` | Spearman 상관 임계값 |
| `--vif-threshold` | `10.0` | VIF 임계값 |
| `--nonlinear-threshold` | `0.85` | 비선형 상관 임계값 |
| `--range-mode` | `minmax` | 범위 계산 방식 (`minmax`, `trimmed`, `iqr`) |

### 3.3 개별 Pass 실행

```bash
# Pass 0: 샘플링
cdml filter pass0 --parquet-glob "data/*.parquet" --output-dir results/

# Pass 1: 통계 및 분산 필터링
cdml filter pass1 --parquet-glob "data/*.parquet" --output-dir results/

# Pass 2-4: 상관 필터링 (Spearman, VIF, HSIC/RDC)
cdml filter pass234 --parquet-glob "data/*.parquet" --output-dir results/

# 전체 Pass 실행
cdml filter all --parquet-glob "data/*.parquet" --output-dir results/
```

---

## 4. Track 2: ML 모델 학습

필터링된 descriptor를 사용하여 ML 모델을 학습합니다.

### 4.1 기본 사용법

```bash
# 기본 실행 (자동 train/test 분할)
cdml train \
    --input Labeled_descriptors.parquet \
    --target-col pLeach \
    --output-dir ml_output/

# 클러스터 정보 활용
cdml train \
    --input Labeled_descriptors.parquet \
    --cluster-info outputs/final_cluster_info.json \
    --target-col pLeach \
    --output-dir ml_output/
```

### 4.2 외부 테스트셋 사용 (신규 기능)

별도의 테스트 파일을 지정하여 더 정확한 성능 평가가 가능합니다:

```bash
# 별도 train/test 파일 사용
cdml train \
    --input train_data.parquet \
    --test-input test_data.parquet \
    --target-col pLeach \
    --output-dir ml_output/
```

> **참고**: `--test-input` 옵션 사용 시 `--test-size`는 무시됩니다.

### 4.3 Descriptor 선택 모드

```bash
# Sequential: 원본 컬럼 순서 (기본)
cdml train --input data.parquet --descriptor-mode sequential

# Representative: 클러스터 대표 descriptor
cdml train --input data.parquet --cluster-info cluster_info.json --descriptor-mode representative

# Random Alternative: 클러스터에서 랜덤 선택
cdml train --input data.parquet --cluster-info cluster_info.json --descriptor-mode random_alternative

# Mixed: 대표 + 대안 혼합
cdml train --input data.parquet --cluster-info cluster_info.json --descriptor-mode mixed
```

### 4.4 `train` 옵션 상세

| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--input` | (필수) | 학습 데이터 파일 (.parquet 또는 .csv) |
| `--test-input` | (없음) | **외부 테스트 데이터 파일** (지정 시 --test-size 무시) |
| `--cluster-info` | (없음) | final_cluster_info.json 경로 |
| `--target-col` | `pLeach` | 예측 타겟 컬럼명 |
| `--output-dir` | `ml_output` | 출력 디렉토리 |
| `--descriptor-sizes` | `5,10,15,20,30,40,50` | 테스트할 descriptor 개수 (쉼표 구분) |
| `--descriptor-mode` | `sequential` | Descriptor 선택 방식 |
| `--models` | (전체) | 학습할 모델 목록 (쉼표 구분) |
| `--test-size` | `0.2` | Hold-out 테스트셋 비율 |
| `--cv-folds` | `5` | K-Fold 교차검증 폴드 수 |
| `--random-seed` | `42` | 랜덤 시드 |
| `--regularization` | `False` | 강한 정규화 적용 (소규모 데이터용) |
| `--no-plots` | `False` | 그래프 생성 건너뛰기 |

### 4.5 지원 모델

| 모델 | 설명 |
|------|------|
| `RandomForest` | Random Forest Regressor |
| `ExtraTrees` | Extra Trees Regressor |
| `XGBoost` | XGBoost Regressor (설치 필요) |
| `LightGBM` | LightGBM Regressor (설치 필요) |
| `Ridge` | Ridge Regression |
| `Lasso` | Lasso Regression |
| `ElasticNet` | ElasticNet Regression |
| `GPR` | Gaussian Process Regressor |

```bash
# 특정 모델만 학습
cdml train --input data.parquet --models "XGBoost,RandomForest,Ridge"
```

---

## 5. 고급 사용법

### 5.1 개별 전처리 단계

```bash
# 1. PubChem XML → Parquet 변환
cdml preprocess xml-to-parquet \
    --input compounds.xml.gz \
    --output molecules.parquet \
    --filter-property "Molecular Weight" \
    --filter-max 500

# 2. Descriptor 스키마 생성
cdml preprocess generate-schema \
    --input data_dir/ \
    --output schema.json \
    --quick

# 3. Descriptor 계산
cdml preprocess calculate-descriptors \
    --input molecules.parquet \
    --output descriptors/ \
    --schema schema.json \
    --timeout 60
```

### 5.2 대규모 데이터 처리

```bash
# 파일당 샘플링 (메모리 절약)
cdml run \
    --parquet-glob "large_data/*.parquet" \
    --output-dir results/ \
    --sample-per-file 10000

# 체크포인트 활성화 (중단 후 재시작 가능)
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/
    # 기본적으로 체크포인트 활성화됨

# 체크포인트 비활성화
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/ \
    --no-checkpoint
```

### 5.3 GPU 설정

```bash
# 특정 GPU 사용
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --gpu-id 1

# CPU 강제 사용
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --cpu
```

---

## 6. 출력 파일 설명

### 6.1 Track 1 출력 (`outputs/`)

| 파일명 | 설명 |
|--------|------|
| `pass0_sample.parquet` | Pass 0 샘플링 결과 |
| `pass1_statistics.json` | Pass 1 통계 정보 |
| `pass1_removed.json` | Pass 1에서 제거된 descriptor |
| `pass2_spearman_clusters.json` | Pass 2 Spearman 클러스터 |
| `pass3_vif_results.json` | Pass 3 VIF 결과 |
| `pass4_nonlinear_results.json` | Pass 4 비선형 결과 |
| `final_descriptors.json` | 최종 선택된 descriptor 목록 |
| `final_cluster_info.json` | 클러스터 정보 (ML 학습용) |
| `pipeline_summary.json` | 파이프라인 요약 |

### 6.2 Track 2 출력 (`ml_output/`)

| 파일명 | 설명 |
|--------|------|
| `ml_results.json` | 전체 실험 결과 |
| `best_model.json` | 최고 성능 모델 정보 |
| `model_comparison_test_r2.png` | 모델별 Test R² 비교 그래프 |
| `kfold_vs_holdout.png` | K-Fold vs Hold-Out 비교 그래프 |
| `descriptor_count_heatmap.png` | Descriptor 수별 성능 히트맵 |

---

## 7. 실행 예시: 전체 워크플로우

### 7.1 예시 데이터셋 정보

`example/` 폴더에 있는 예시 데이터를 사용하여 **처음부터 끝까지** 전체 워크플로우를 실행한 결과입니다.

| 파일 | 샘플 수 | 설명 |
|------|---------|------|
| `Ligand_U_leaching_sample.csv` | 77 | **Track 1 입력**: SMILES가 포함된 원본 분자 데이터 |
| `train_samples_61.csv` | 61 | **Track 2 학습 데이터**: descriptor가 포함된 학습셋 |
| `test_samples_16.csv` | 16 | **Track 2 테스트 데이터**: 외부 검증용 테스트셋 |

### 7.2 Step 1: Track 1 - Descriptor 계산 및 필터링

먼저 SMILES 데이터로부터 descriptor를 계산하고 필터링합니다.

```bash
cdml process-all \
    --input example/Ligand_U_leaching_sample.csv \
    --output-dir output/track1_output \
    --smiles-col smiles \
    --id-col ligand_name \
    --variance-threshold 0.0004 \
    --max-missing-ratio 0.15 \
    --min-effective-n 10 \
    --spearman-threshold 0.85 \
    --vif-threshold 7.0 \
    --cpu
```

**필터링 파라미터 설명:**
| 파라미터 | 값 | 설명 |
|----------|-----|------|
| `--variance-threshold` | 0.0004 | 최소 정규화 분산 |
| `--max-missing-ratio` | 0.15 | 최대 결측치 비율 (15%) |
| `--min-effective-n` | 10 | 최소 유효 샘플 수 |
| `--spearman-threshold` | 0.85 | Spearman 상관 클러스터링 임계값 |
| `--vif-threshold` | 7.0 | VIF 다중공선성 임계값 |

**Track 1 결과:**
- 입력: 77개 분자
- 계산된 Descriptor: 1,775개
- **최종 Descriptor: 71개** (4단계 필터링 후)

**출력 파일 구조:**
```
output/track1_output/
├── outputs/
│   ├── final_cluster_info.json    # 클러스터 정보 (Track 2에서 사용)
│   ├── final_descriptors.txt      # 최종 71개 descriptor 목록
│   ├── descriptors.parquet        # 계산된 descriptor 데이터
│   └── descriptor_schema.json     # 스키마
├── train_with_new_descriptors.csv # pLeach 매칭된 학습 데이터 (61개)
├── test_with_new_descriptors.csv  # pLeach 매칭된 테스트 데이터 (16개)
├── tmp/                           # 중간 결과
└── process_all.log                # 실행 로그
```

### 7.3 Step 2: Train/Test 데이터 생성

Track 1에서 계산된 descriptor에 pLeach 값을 매칭하여 train/test 세트를 생성합니다.
(기존 `train_samples_61.csv`와 `test_samples_16.csv`의 pLeach 값 기준으로 분류)

```python
# pLeach 매칭으로 train/test 생성 (Python)
import pandas as pd

desc_df = pd.read_parquet('output/track1_output/outputs/descriptors.parquet')
full_df = pd.read_csv('example/Ligand_U_leaching_sample.csv')
train_orig = pd.read_csv('example/train_samples_61.csv')
test_orig = pd.read_csv('example/test_samples_16.csv')

# pLeach 병합
desc_df = desc_df.merge(full_df[['ligand_name', 'pLeach']],
                        left_on='CID', right_on='ligand_name')

# pLeach 기준으로 train/test 분류
train_new = desc_df[desc_df['pLeach'].round(10).isin(train_orig['pLeach'].round(10))]
test_new = desc_df[desc_df['pLeach'].round(10).isin(test_orig['pLeach'].round(10))]

train_new.to_csv('output/track1_output/train_with_new_descriptors.csv', index=False)
test_new.to_csv('output/track1_output/test_with_new_descriptors.csv', index=False)
```

### 7.4 Step 3: Track 2 - ML 모델 학습

Track 1에서 생성된 클러스터 정보와 새 descriptor로 ML 모델을 학습합니다.

```bash
cdml train \
    --input output/track1_output/train_with_new_descriptors.csv \
    --test-input output/track1_output/test_with_new_descriptors.csv \
    --cluster-info output/track1_output/outputs/final_cluster_info.json \
    --target-col pLeach \
    --output-dir output/track2_output \
    --descriptor-sizes 5,10,15,20,30,40,50 \
    --descriptor-mode representative \
    --no-plots
```

**Track 2 실행 내용:**
- 8개 모델 × 7개 descriptor 크기 = **56개 실험** 수행
- 모델: RandomForest, ExtraTrees, Ridge, Lasso, ElasticNet, XGBoost, LightGBM, GPR
- Descriptor 크기: 5, 10, 15, 20, 30, 40, 50
- 선택 모드: `representative` (클러스터 대표 descriptor 사용)

**Track 2 결과:**

| 최적 모델 | LightGBM |
|-----------|----------|
| Descriptor 수 | 10 |
| K-Fold R² | -0.0353 ± 0.2826 |
| **Hold-Out R²** | **0.4993** |
| Hold-Out RMSE | 1.871 |
| Overfitting Gap | -0.3037 |

**출력 파일 구조:**
```
output/track2_output/
├── best_model.json      # 최고 성능 모델 정보
├── ml_results.json      # 전체 56개 실험 결과
└── train.log            # 학습 로그
```

### 7.5 전체 출력 폴더 구조

```
output/
├── track1_output/                          # Track 1 결과
│   ├── outputs/
│   │   ├── final_cluster_info.json         # 클러스터 정보
│   │   ├── final_descriptors.txt           # 71개 최종 descriptor
│   │   ├── descriptors.parquet             # 77 × 1775 descriptor 데이터
│   │   └── descriptor_schema.json          # 스키마
│   ├── train_with_new_descriptors.csv      # 61개 학습 샘플
│   ├── test_with_new_descriptors.csv       # 16개 테스트 샘플
│   ├── tmp/                                # 중간 결과
│   └── process_all.log                     # 로그
│
└── track2_output/                          # Track 2 결과
    ├── best_model.json                     # LightGBM, 10D, R²=0.4993
    ├── ml_results.json                     # 56개 실험 결과
    └── train.log                           # 로그
```

### 7.6 주요 실험 결과 (상위 성능)

| 순위 | 모델 | Descriptors | K-Fold R² | Hold-Out R² |
|------|------|-------------|-----------|-------------|
| 1 | **LightGBM** | **10** | -0.0353 | **0.4993** |
| 2 | LightGBM | 5 | -0.0271 | 0.4899 |
| 3 | XGBoost | 10 | -0.6868 | 0.3748 |
| 4 | RandomForest | 5 | -0.2035 | 0.3703 |
| 5 | RandomForest | 50 | -0.1883 | 0.3672 |

### 7.7 소규모 데이터셋 분석

**왜 K-Fold R²가 낮고 Hold-Out R²가 높은가?**

- 61개 학습 샘플로 5-Fold CV 수행 시 각 폴드당 ~12개 샘플만 사용
- 소규모 데이터셋에서는 CV가 불안정하며 분산이 큼
- 16개 테스트 샘플이 우연히 잘 맞는 패턴을 가질 수 있음
- **Overfitting Gap이 음수** = 테스트 성능이 CV보다 좋음 (일반적이지 않음)

**권장사항:**
- 더 많은 데이터 수집
- 더 적은 descriptor 사용 (과적합 방지)
- 여러 random seed로 실험하여 안정성 확인

---

## 8. 문제 해결

### 8.1 일반적인 오류

**오류: "No descriptors remaining after Pass1"**
```bash
# 해결: 최소 유효 샘플 수 감소
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --min-effective-n 30
```

**오류: GPU 메모리 부족**
```bash
# 해결: CPU 모드 사용 또는 샘플링
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --cpu
# 또는
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --sample-per-file 5000
```

**오류: "XGBoost/LightGBM not found"**
```bash
# 해결: 패키지 설치
pip install xgboost lightgbm
```

### 8.2 성능 최적화

1. **GPU 사용**: 가능한 경우 GPU 모드 사용 (기본)
2. **샘플링**: 대규모 데이터는 `--sample-per-file` 사용
3. **병렬 처리**: 여러 파일은 자동 병렬 처리됨

### 8.3 로그 확인

```bash
# 상세 로그 출력
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --verbose
```

---

## 부록: 전체 워크플로우 예시

### A. 통합 실행 (Track 1 + Track 2)

```bash
# 1. 환경 활성화
conda activate cdml

# 2. Track 1: Descriptor 추출 및 필터링
cdml process-all \
    --input molecules.csv \
    --output-dir track1_output/ \
    --smiles-col SMILES \
    --id-col CID \
    --verbose

# 3. Track 2: ML 모델 학습
cdml train \
    --input Labeled_descriptors.parquet \
    --cluster-info track1_output/outputs/final_cluster_info.json \
    --target-col pLeach \
    --output-dir track2_output/ \
    --descriptor-sizes "5,10,15,20,30,40,50" \
    --descriptor-mode random_alternative

# 4. 결과 확인
cat track2_output/best_model.json
```

### B. 별도 Train/Test 데이터로 실행

```bash
# 1. ML 학습 (별도 테스트셋 사용)
cdml train \
    --input train_data.csv \
    --test-input test_data.csv \
    --target-col pLeach \
    --output-dir ml_results/ \
    --descriptor-sizes "5,10,15,20,30" \
    --models "XGBoost,RandomForest,Ridge,LightGBM"

# 2. 결과 확인
cat ml_results/best_model.json
```
