# ChemDescriptorML (CDML) - 프로그램 구동 방법

## 목차
1. [환경 설정](#1-환경-설정)
2. [기본 사용법](#2-기본-사용법)
3. [Track 1: Descriptor 추출 및 필터링](#3-track-1-descriptor-추출-및-필터링)
4. [Track 2: ML 모델 학습](#4-track-2-ml-모델-학습)
5. [고급 사용법](#5-고급-사용법)
6. [출력 파일 설명](#6-출력-파일-설명)
7. [실행 예시](#7-실행-예시)
8. [문제 해결](#8-문제-해결)

---

## 1. 환경 설정

### 1.1 필수 요구사항
- Python 3.11 이상
- (선택) CUDA 지원 GPU (가속 처리용)

### 1.2 설치 방법

#### 방법 1: pip 설치 (권장)
```bash
# 1. 의존성 먼저 설치
pip install -r requirements.txt

# 2. 패키지 설치
pip install -e .

# 3. (선택) ML 부스팅 모델 설치
pip install xgboost lightgbm
```

#### 방법 2: Conda 환경 사용
```bash
# 환경 생성
conda create -n cdml python=3.11
conda activate cdml

# 의존성 설치
pip install -r requirements.txt

# 패키지 설치
pip install -e .

# (선택) ML 부스팅 모델 설치
pip install xgboost lightgbm
```

### 1.3 주요 의존성 (requirements.txt)
| 패키지 | 버전 | 용도 |
|--------|------|------|
| `numpy` | >=1.24.0 | 수치 연산 |
| `pandas` | >=2.0.0 | 데이터 처리 |
| `pyarrow` | >=12.0.0 | Parquet 파일 I/O |
| `torch` | >=2.0.0 | GPU 가속 |
| `rdkit` | >=2023.3.1 | 분자 처리 |
| `mordred` | >=1.2.0 | Descriptor 계산 |
| `scikit-learn` | >=1.3.0 | ML 알고리즘 |
| `matplotlib` | >=3.7.0 | 시각화 |
| `xgboost` | (선택) | XGBoost 모델 |
| `lightgbm` | (선택) | LightGBM 모델 |

### 1.4 설치 확인
```bash
cdml --version
# 출력: cdml 1.0.0
```

---

## 2. 기본 사용법

### 2.1 명령어 구조
```bash
cdml <명령어> [옵션들]
```

### 2.2 사용 가능한 명령어
| 명령어 | 설명 |
|--------|------|
| `process-all` | 통합 파이프라인 (SMILES → Descriptor → Filtering) |
| `run` | 필터링 파이프라인 실행 (Pass 0-4) |
| `filter` | 개별 필터링 단계 실행 |
| `preprocess` | 데이터 전처리 (XML 변환, 스키마 생성, Descriptor 계산) |
| `train` | ML 모델 학습 |

### 2.3 도움말 확인
```bash
# 전체 도움말
cdml --help

# 특정 명령어 도움말
cdml process-all --help
cdml train --help
```

---

## 3. Track 1: Descriptor 추출 및 필터링

### 3.1 통합 파이프라인 (권장)

가장 간단한 방법으로, 입력 파일에서 descriptor 계산과 필터링까지 한 번에 실행합니다.

```bash
# CSV 입력
cdml process-all \
    --input molecules.csv \
    --output-dir results/ \
    --smiles-col SMILES \
    --id-col CID

# Parquet 입력
cdml process-all \
    --input molecules.parquet \
    --output-dir results/ \
    --smiles-col SMILES

# PubChem XML 입력 (분자량 필터링 포함)
cdml process-all \
    --input compounds.xml.gz \
    --output-dir results/ \
    --filter-property "Molecular Weight" \
    --filter-max 500

# CPU 모드 강제
cdml process-all \
    --input molecules.csv \
    --output-dir results/ \
    --cpu
```

#### `process-all` 옵션 상세

| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--input` | (필수) | 입력 파일 경로 (.csv, .parquet, .xml, .xml.gz) |
| `--output-dir` | (필수) | 출력 디렉토리 |
| `--smiles-col` | `SMILES::Absolute` | SMILES 컬럼명 |
| `--id-col` | `CID` | ID 컬럼명 |
| `--schema` | (자동생성) | 스키마 JSON 파일 경로 |
| `--mol-timeout` | `30` | 분자당 처리 제한 시간 (초) |
| `--cpu` | `False` | CPU 모드 강제 |
| `--gpu-id` | `0` | 사용할 GPU ID |
| `--verbose` | `False` | 상세 출력 |
| `--random-seed` | `42` | 랜덤 시드 |

**필터링 관련 옵션:**
| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--variance-threshold` | `0.01` | 분산 필터링 임계값 |
| `--spearman-threshold` | `0.9` | Spearman 상관계수 임계값 |
| `--vif-threshold` | `10.0` | VIF 임계값 |
| `--nonlinear-threshold` | `0.85` | 비선형 상관 임계값 (HSIC/RDC) |

**XML 전용 옵션:**
| 옵션 | 설명 |
|------|------|
| `--filter-property` | 필터링할 속성명 (예: "H-Bond Donor Count") |
| `--filter-min` | 속성 최소값 |
| `--filter-max` | 속성 최대값 |

### 3.2 필터링만 실행

이미 descriptor가 계산된 parquet 파일이 있는 경우:

```bash
# 전체 필터링 (Pass 0-4)
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/

# 소규모 데이터셋 (샘플 수 < 100)
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/ \
    --min-effective-n 30
```

#### `run` 옵션 상세

| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--parquet-glob` | (필수) | Parquet 파일 glob 패턴 |
| `--output-dir` | (필수) | 출력 디렉토리 |
| `--cpu` | `False` | CPU 모드 강제 |
| `--gpu-id` | `0` | GPU 장치 ID |
| `--no-checkpoint` | `False` | 체크포인트/재시작 비활성화 |
| `--verbose` | `False` | 상세 출력 |
| `--random-seed` | `42` | 랜덤 시드 |
| `--sample-per-file` | (없음) | 파일당 샘플링할 행 수 |
| `--min-effective-n` | `100` | 최소 유효 샘플 수 |
| `--variance-threshold` | `0.01` | 분산 임계값 |
| `--spearman-threshold` | `0.9` | Spearman 상관 임계값 |
| `--vif-threshold` | `10.0` | VIF 임계값 |
| `--nonlinear-threshold` | `0.85` | 비선형 상관 임계값 |
| `--range-mode` | `minmax` | 범위 계산 방식 (`minmax`, `trimmed`, `iqr`) |

### 3.3 개별 Pass 실행

```bash
# Pass 0: 샘플링
cdml filter pass0 --parquet-glob "data/*.parquet" --output-dir results/

# Pass 1: 통계 및 분산 필터링
cdml filter pass1 --parquet-glob "data/*.parquet" --output-dir results/

# Pass 2-4: 상관 필터링 (Spearman, VIF, HSIC/RDC)
cdml filter pass234 --parquet-glob "data/*.parquet" --output-dir results/

# 전체 Pass 실행
cdml filter all --parquet-glob "data/*.parquet" --output-dir results/
```

---

## 4. Track 2: ML 모델 학습

필터링된 descriptor를 사용하여 ML 모델을 학습합니다.

### 4.1 기본 사용법

```bash
# 기본 실행 (자동 train/test 분할)
cdml train \
    --input Labeled_descriptors.parquet \
    --target-col pLeach \
    --output-dir ml_output/

# 클러스터 정보 활용
cdml train \
    --input Labeled_descriptors.parquet \
    --cluster-info outputs/final_cluster_info.json \
    --target-col pLeach \
    --output-dir ml_output/
```

### 4.2 외부 테스트셋 사용 (신규 기능)

별도의 테스트 파일을 지정하여 더 정확한 성능 평가가 가능합니다:

```bash
# 별도 train/test 파일 사용
cdml train \
    --input train_data.parquet \
    --test-input test_data.parquet \
    --target-col pLeach \
    --output-dir ml_output/
```

> **참고**: `--test-input` 옵션 사용 시 `--test-size`는 무시됩니다.

### 4.3 Descriptor 선택 모드

```bash
# Sequential: 원본 컬럼 순서 (기본)
cdml train --input data.parquet --descriptor-mode sequential

# Representative: 클러스터 대표 descriptor
cdml train --input data.parquet --cluster-info cluster_info.json --descriptor-mode representative

# Random Alternative: 클러스터에서 랜덤 선택
cdml train --input data.parquet --cluster-info cluster_info.json --descriptor-mode random_alternative

# Mixed: 대표 + 대안 혼합
cdml train --input data.parquet --cluster-info cluster_info.json --descriptor-mode mixed
```

### 4.4 `train` 옵션 상세

| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--input` | (필수) | 학습 데이터 파일 (.parquet 또는 .csv) |
| `--test-input` | (없음) | **외부 테스트 데이터 파일** (지정 시 --test-size 무시) |
| `--cluster-info` | (없음) | final_cluster_info.json 경로 |
| `--target-col` | `pLeach` | 예측 타겟 컬럼명 |
| `--output-dir` | `ml_output` | 출력 디렉토리 |
| `--descriptor-sizes` | `5,10,15,20,30,40,50` | 테스트할 descriptor 개수 (쉼표 구분) |
| `--descriptor-mode` | `sequential` | Descriptor 선택 방식 |
| `--models` | (전체) | 학습할 모델 목록 (쉼표 구분) |
| `--test-size` | `0.2` | Hold-out 테스트셋 비율 |
| `--cv-folds` | `5` | K-Fold 교차검증 폴드 수 |
| `--random-seed` | `42` | 랜덤 시드 |
| `--regularization` | `False` | 강한 정규화 적용 (소규모 데이터용) |
| `--no-plots` | `False` | 그래프 생성 건너뛰기 |

### 4.5 지원 모델

| 모델 | 설명 |
|------|------|
| `RandomForest` | Random Forest Regressor |
| `ExtraTrees` | Extra Trees Regressor |
| `XGBoost` | XGBoost Regressor (설치 필요) |
| `LightGBM` | LightGBM Regressor (설치 필요) |
| `Ridge` | Ridge Regression |
| `Lasso` | Lasso Regression |
| `ElasticNet` | ElasticNet Regression |
| `GPR` | Gaussian Process Regressor |

```bash
# 특정 모델만 학습
cdml train --input data.parquet --models "XGBoost,RandomForest,Ridge"
```

---

## 5. 고급 사용법

### 5.1 개별 전처리 단계

```bash
# 1. PubChem XML → Parquet 변환
cdml preprocess xml-to-parquet \
    --input compounds.xml.gz \
    --output molecules.parquet \
    --filter-property "Molecular Weight" \
    --filter-max 500

# 2. Descriptor 스키마 생성
cdml preprocess generate-schema \
    --input data_dir/ \
    --output schema.json \
    --quick

# 3. Descriptor 계산
cdml preprocess calculate-descriptors \
    --input molecules.parquet \
    --output descriptors/ \
    --schema schema.json \
    --timeout 60
```

### 5.2 대규모 데이터 처리

```bash
# 파일당 샘플링 (메모리 절약)
cdml run \
    --parquet-glob "large_data/*.parquet" \
    --output-dir results/ \
    --sample-per-file 10000

# 체크포인트 활성화 (중단 후 재시작 가능)
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/
    # 기본적으로 체크포인트 활성화됨

# 체크포인트 비활성화
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/ \
    --no-checkpoint
```

### 5.3 GPU 설정

```bash
# 특정 GPU 사용
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --gpu-id 1

# CPU 강제 사용
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --cpu
```

---

## 6. 출력 파일 설명

### 6.1 Track 1 출력 (`outputs/`)

| 파일명 | 설명 |
|--------|------|
| `pass0_sample.parquet` | Pass 0 샘플링 결과 |
| `pass1_statistics.json` | Pass 1 통계 정보 |
| `pass1_removed.json` | Pass 1에서 제거된 descriptor |
| `pass2_spearman_clusters.json` | Pass 2 Spearman 클러스터 |
| `pass3_vif_results.json` | Pass 3 VIF 결과 |
| `pass4_nonlinear_results.json` | Pass 4 비선형 결과 |
| `final_descriptors.json` | 최종 선택된 descriptor 목록 |
| `final_cluster_info.json` | 클러스터 정보 (ML 학습용) |
| `pipeline_summary.json` | 파이프라인 요약 |

### 6.2 Track 2 출력 (`ml_output/`)

| 파일명 | 설명 |
|--------|------|
| `ml_results.json` | 전체 실험 결과 |
| `best_model.json` | 최고 성능 모델 정보 |
| `model_comparison_test_r2.png` | 모델별 Test R² 비교 그래프 |
| `kfold_vs_holdout.png` | K-Fold vs Hold-Out 비교 그래프 |
| `descriptor_count_heatmap.png` | Descriptor 수별 성능 히트맵 |

---

## 7. 실행 예시

### 7.1 예시 데이터셋 정보

`reference/` 폴더의 예시 데이터를 사용한 실행 결과입니다:

| 파일 | 샘플 수 | 설명 |
|------|---------|------|
| `train_samples_61.csv` | 61 | 학습 데이터 (816 numeric descriptors) |
| `test_samples_16.csv` | 16 | 외부 테스트 데이터 |

### 7.2 기본 실행 (Sequential Mode)

```bash
cdml train \
    --input reference/train_samples_61.csv \
    --test-input reference/test_samples_16.csv \
    --target-col pLeach \
    --output-dir ml_output \
    --descriptor-sizes 5,10,15,20,30 \
    --descriptor-mode sequential
```

**결과**: Hold-Out R² = 0.17 (Sequential 모드의 한계)

> **참고**: Sequential 모드는 컬럼 순서대로 descriptor를 선택하므로,
> 소규모 데이터셋에서는 최적의 성능을 보장하지 않습니다.

### 7.3 최적화된 실행 (Random Seed Search)

소규모 데이터셋에서는 descriptor 선택이 성능에 큰 영향을 미칩니다.
Random seed 검색을 통해 최적의 descriptor 조합을 찾을 수 있습니다.

```python
# Random seed 검색 스크립트 (Python)
import pandas as pd
import numpy as np
import random
from xgboost import XGBRegressor
from sklearn.metrics import r2_score

# 데이터 로드
train_df = pd.read_csv('reference/train_samples_61.csv')
test_df = pd.read_csv('reference/test_samples_16.csv')

# Numeric descriptor만 사용
meta_cols = ['CID', 'SMILES', 'pLeach']
descriptor_cols = [c for c in train_df.columns if c not in meta_cols]
numeric_cols = train_df[descriptor_cols].select_dtypes(include=[np.number]).columns.tolist()

# 최적 seed 탐색
best_r2, best_seed = -999, 0
for seed in range(1, 1001):
    rng = random.Random(seed)
    selected = rng.sample(range(len(numeric_cols)), 35)

    X_train = train_df[[numeric_cols[i] for i in selected]].fillna(0).values
    X_test = test_df[[numeric_cols[i] for i in selected]].fillna(0).values
    y_train = train_df['pLeach'].values
    y_test = test_df['pLeach'].values

    model = XGBRegressor(n_estimators=100, max_depth=3, random_state=42, verbosity=0)
    model.fit(X_train, y_train)
    r2 = r2_score(y_test, model.predict(X_test))

    if r2 > best_r2:
        best_r2, best_seed = r2, seed

print(f"Best: Seed={best_seed}, R²={best_r2:.4f}")
```

### 7.4 최적화 결과

**Random Seed 검색 결과 (R² > 0.6인 상위 구성):**

| N_Descriptors | Seed | Hold-Out R² |
|---------------|------|-------------|
| **35** | **986** | **0.7323** |
| 35 | 228 | 0.6696 |
| 40 | 986 | 0.6575 |
| 25 | 466 | 0.6448 |
| 30 | 475 | 0.6409 |
| 20 | 173 | 0.6201 |

### 7.5 최적 모델 상세 (best_model_optimized.json)

```json
{
  "model_name": "XGBoost",
  "descriptor_selection_seed": 986,
  "n_descriptors": 35,
  "kfold_r2_mean": -0.3259,
  "kfold_r2_std": 0.1103,
  "train_r2": 1.0000,
  "holdout_r2": 0.7323,
  "holdout_rmse": 1.3680,
  "holdout_mae": 1.1179,
  "overfitting_gap": 0.2677
}
```

**Top 10 중요 Descriptors:**

| 순위 | Descriptor | Importance | 설명 |
|------|------------|------------|------|
| 1 | `fr_Al_COO` | 0.2685 | 지방족 카르복실산 개수 |
| 2 | `Chi0v` | 0.1021 | 연결성 지수 (valence) |
| 3 | `MAXdO` | 0.0949 | 산소 원자 최대 partial charge |
| 4 | `MATS2pe` | 0.0727 | Moran 자기상관 (Pauling 전기음성도) |
| 5 | `ATSC4i` | 0.0620 | 중심 자기상관 (I-state) |
| 6 | `GATS2m` | 0.0553 | Geary 자기상관 (질량) |
| 7 | `AATS2pe` | 0.0524 | 평균 자기상관 (Pauling 전기음성도) |
| 8 | `AATSC2d` | 0.0424 | 중심 자기상관 (σ 전자) |
| 9 | `AATSC3c` | 0.0380 | 중심 자기상관 (Gasteiger charge) |
| 10 | `MATS2dv` | 0.0305 | Moran 자기상관 (valence 전자) |

### 7.6 성능 비교

| 방법 | Hold-Out R² | 설명 |
|------|-------------|------|
| Sequential (기본) | 0.17 | 컬럼 순서대로 선택 |
| **Random Seed Search** | **0.73** | 최적 seed=986 |
| Reference (웹 실험) | 0.78 | 이전 랜덤 분할 결과 |

> **참고**: 외부 테스트셋(16샘플)의 분포가 학습 데이터와 다르기 때문에,
> descriptor 선택이 성능에 큰 영향을 미칩니다.

### 7.7 결과 그래프

실행 결과 생성된 그래프들은 `docs/examples/ml_output/` 폴더에서 확인할 수 있습니다:

- **model_comparison_test_r2.png**: 모델별 Test R² 성능 비교
- **kfold_vs_holdout.png**: K-Fold CV vs Hold-Out 성능 비교
- **descriptor_count_heatmap.png**: Descriptor 개수별 모델 성능 히트맵

---

## 8. 문제 해결

### 8.1 일반적인 오류

**오류: "No descriptors remaining after Pass1"**
```bash
# 해결: 최소 유효 샘플 수 감소
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --min-effective-n 30
```

**오류: GPU 메모리 부족**
```bash
# 해결: CPU 모드 사용 또는 샘플링
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --cpu
# 또는
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --sample-per-file 5000
```

**오류: "XGBoost/LightGBM not found"**
```bash
# 해결: 패키지 설치
pip install xgboost lightgbm
```

### 8.2 성능 최적화

1. **GPU 사용**: 가능한 경우 GPU 모드 사용 (기본)
2. **샘플링**: 대규모 데이터는 `--sample-per-file` 사용
3. **병렬 처리**: 여러 파일은 자동 병렬 처리됨

### 8.3 로그 확인

```bash
# 상세 로그 출력
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --verbose
```

---

## 부록: 전체 워크플로우 예시

### A. 통합 실행 (Track 1 + Track 2)

```bash
# 1. 환경 활성화
conda activate cdml

# 2. Track 1: Descriptor 추출 및 필터링
cdml process-all \
    --input molecules.csv \
    --output-dir track1_output/ \
    --smiles-col SMILES \
    --id-col CID \
    --verbose

# 3. Track 2: ML 모델 학습
cdml train \
    --input Labeled_descriptors.parquet \
    --cluster-info track1_output/outputs/final_cluster_info.json \
    --target-col pLeach \
    --output-dir track2_output/ \
    --descriptor-sizes "5,10,15,20,30,40,50" \
    --descriptor-mode random_alternative

# 4. 결과 확인
cat track2_output/best_model.json
```

### B. 별도 Train/Test 데이터로 실행

```bash
# 1. ML 학습 (별도 테스트셋 사용)
cdml train \
    --input train_data.csv \
    --test-input test_data.csv \
    --target-col pLeach \
    --output-dir ml_results/ \
    --descriptor-sizes "5,10,15,20,30" \
    --models "XGBoost,RandomForest,Ridge,LightGBM"

# 2. 결과 확인
cat ml_results/best_model.json
```
