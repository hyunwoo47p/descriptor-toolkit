# ChemDescriptorML (CDML) - 프로그램 구동 방법

## 목차
1. [환경 설정](#1-환경-설정)
2. [기본 사용법](#2-기본-사용법)
3. [Track 1: Descriptor 추출 및 필터링](#3-track-1-descriptor-추출-및-필터링)
4. [Track 2: ML 모델 학습](#4-track-2-ml-모델-학습)
5. [고급 사용법](#5-고급-사용법)
6. [출력 파일 설명](#6-출력-파일-설명)
7. [실행 예시](#7-실행-예시)
8. [문제 해결](#8-문제-해결)

---

## 1. 환경 설정

### 1.1 필수 요구사항
- Python 3.11 이상
- (선택) CUDA 지원 GPU (가속 처리용)

### 1.2 설치 방법

#### 방법 1: pip 설치 (권장)
```bash
# 1. 의존성 먼저 설치
pip install -r requirements.txt

# 2. 패키지 설치
pip install -e .

# 3. (선택) ML 부스팅 모델 설치
pip install xgboost lightgbm
```

#### 방법 2: Conda 환경 사용
```bash
# 환경 생성
conda create -n cdml python=3.11
conda activate cdml

# 의존성 설치
pip install -r requirements.txt

# 패키지 설치
pip install -e .

# (선택) ML 부스팅 모델 설치
pip install xgboost lightgbm
```

### 1.3 주요 의존성 (requirements.txt)
| 패키지 | 버전 | 용도 |
|--------|------|------|
| `numpy` | >=1.24.0 | 수치 연산 |
| `pandas` | >=2.0.0 | 데이터 처리 |
| `pyarrow` | >=12.0.0 | Parquet 파일 I/O |
| `torch` | >=2.0.0 | GPU 가속 |
| `rdkit` | >=2023.3.1 | 분자 처리 |
| `mordred` | >=1.2.0 | Descriptor 계산 |
| `scikit-learn` | >=1.3.0 | ML 알고리즘 |
| `matplotlib` | >=3.7.0 | 시각화 |
| `xgboost` | (선택) | XGBoost 모델 |
| `lightgbm` | (선택) | LightGBM 모델 |

### 1.4 설치 확인
```bash
cdml --version
# 출력: cdml 1.0.0
```

---

## 2. 기본 사용법

### 2.1 명령어 구조
```bash
cdml <명령어> [옵션들]
```

### 2.2 사용 가능한 명령어
| 명령어 | 설명 |
|--------|------|
| `process-all` | 통합 파이프라인 (SMILES → Descriptor → Filtering) |
| `run` | 필터링 파이프라인 실행 (Pass 0-4) |
| `filter` | 개별 필터링 단계 실행 |
| `preprocess` | 데이터 전처리 (XML 변환, 스키마 생성, Descriptor 계산) |
| `train` | ML 모델 학습 |

### 2.3 도움말 확인
```bash
# 전체 도움말
cdml --help

# 특정 명령어 도움말
cdml process-all --help
cdml train --help
```

---

## 3. Track 1: Descriptor 추출 및 필터링

### 3.1 통합 파이프라인 (권장)

가장 간단한 방법으로, 입력 파일에서 descriptor 계산과 필터링까지 한 번에 실행합니다.

```bash
# CSV 입력
cdml process-all \
    --input molecules.csv \
    --output-dir results/ \
    --smiles-col SMILES \
    --id-col CID

# Parquet 입력
cdml process-all \
    --input molecules.parquet \
    --output-dir results/ \
    --smiles-col SMILES

# PubChem XML 입력 (분자량 필터링 포함)
cdml process-all \
    --input compounds.xml.gz \
    --output-dir results/ \
    --filter-property "Molecular Weight" \
    --filter-max 500

# CPU 모드 강제
cdml process-all \
    --input molecules.csv \
    --output-dir results/ \
    --cpu
```

#### `process-all` 옵션 상세

| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--input` | (필수) | 입력 파일 경로 (.csv, .parquet, .xml, .xml.gz) |
| `--output-dir` | (필수) | 출력 디렉토리 |
| `--smiles-col` | `SMILES::Absolute` | SMILES 컬럼명 |
| `--id-col` | `CID` | ID 컬럼명 |
| `--schema` | (자동생성) | 스키마 JSON 파일 경로 |
| `--mol-timeout` | `30` | 분자당 처리 제한 시간 (초) |
| `--cpu` | `False` | CPU 모드 강제 |
| `--gpu-id` | `0` | 사용할 GPU ID |
| `--verbose` | `False` | 상세 출력 |
| `--random-seed` | `42` | 랜덤 시드 |

**필터링 관련 옵션:**
| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--variance-threshold` | `0.01` | 분산 필터링 임계값 |
| `--max-missing-ratio` | `0.30` | 최대 결측치 비율 |
| `--spearman-threshold` | `0.75` | Spearman 상관계수 임계값 |
| `--vif-threshold` | `10.0` | VIF 임계값 |
| `--nonlinear-threshold` | `0.85` | 비선형 상관 임계값 (HSIC/RDC) |

**XML 전용 옵션:**
| 옵션 | 설명 |
|------|------|
| `--filter-property` | 필터링할 속성명 (예: "H-Bond Donor Count") |
| `--filter-min` | 속성 최소값 |
| `--filter-max` | 속성 최대값 |

### 3.2 필터링만 실행

이미 descriptor가 계산된 parquet 파일이 있는 경우:

```bash
# 전체 필터링 (Pass 0-4)
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/

# 소규모 데이터셋 (샘플 수 < 100)
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/ \
    --min-effective-n 30
```

#### `run` 옵션 상세

| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--parquet-glob` | (필수) | Parquet 파일 glob 패턴 |
| `--output-dir` | (필수) | 출력 디렉토리 |
| `--cpu` | `False` | CPU 모드 강제 |
| `--gpu-id` | `0` | GPU 장치 ID |
| `--no-checkpoint` | `False` | 체크포인트/재시작 비활성화 |
| `--verbose` | `False` | 상세 출력 |
| `--random-seed` | `42` | 랜덤 시드 |
| `--sample-per-file` | (없음) | 파일당 샘플링할 행 수 |
| `--min-effective-n` | `100` | 최소 유효 샘플 수 |
| `--variance-threshold` | `0.01` | 분산 임계값 |
| `--spearman-threshold` | `0.75` | Spearman 상관 임계값 |
| `--vif-threshold` | `10.0` | VIF 임계값 |
| `--nonlinear-threshold` | `0.85` | 비선형 상관 임계값 |
| `--range-mode` | `minmax` | 범위 계산 방식 (`minmax`, `trimmed`, `iqr`) |

### 3.3 개별 Pass 실행

```bash
# Pass 0: 샘플링
cdml filter pass0 --parquet-glob "data/*.parquet" --output-dir results/

# Pass 1: 통계 및 분산 필터링
cdml filter pass1 --parquet-glob "data/*.parquet" --output-dir results/

# Pass 2-4: 상관 필터링 (Spearman, VIF, HSIC/RDC)
cdml filter pass234 --parquet-glob "data/*.parquet" --output-dir results/

# 전체 Pass 실행
cdml filter all --parquet-glob "data/*.parquet" --output-dir results/
```

---

## 4. Track 2: ML 모델 학습

필터링된 descriptor를 사용하여 ML 모델을 학습합니다.

### 4.1 기본 사용법

```bash
# 기본 실행 (자동 train/test 분할)
cdml train \
    --input Labeled_descriptors.parquet \
    --target-col pLeach \
    --output-dir ml_output/

# 클러스터 정보 활용
cdml train \
    --input Labeled_descriptors.parquet \
    --cluster-info outputs/final_cluster_info.json \
    --target-col pLeach \
    --output-dir ml_output/
```

### 4.2 외부 테스트셋 사용

별도의 테스트 파일을 지정하여 더 정확한 성능 평가가 가능합니다:

```bash
# 별도 train/test 파일 사용
cdml train \
    --input train_data.csv \
    --test-input test_data.csv \
    --target-col pLeach \
    --output-dir ml_output/
```

> **참고**: `--test-input` 옵션 사용 시 `--test-size`는 무시됩니다.

### 4.3 Descriptor 선택 모드

```bash
# Sequential: 원본 컬럼 순서 (기본)
cdml train --input data.parquet --descriptor-mode sequential

# Representative: 클러스터 대표 descriptor
cdml train --input data.parquet --cluster-info cluster_info.json --descriptor-mode representative

# Random Alternative: 클러스터에서 랜덤 선택
cdml train --input data.parquet --cluster-info cluster_info.json --descriptor-mode random_alternative

# Mixed: 대표 + 대안 혼합
cdml train --input data.parquet --cluster-info cluster_info.json --descriptor-mode mixed
```

### 4.4 `train` 옵션 상세

| 옵션 | 기본값 | 설명 |
|------|--------|------|
| `--input` | (필수) | 학습 데이터 파일 (.parquet 또는 .csv) |
| `--test-input` | (없음) | **외부 테스트 데이터 파일** (지정 시 --test-size 무시) |
| `--cluster-info` | (없음) | final_cluster_info.json 경로 |
| `--target-col` | `pLeach` | 예측 타겟 컬럼명 |
| `--output-dir` | `ml_output` | 출력 디렉토리 |
| `--descriptor-sizes` | `5,10,15,20,30,40,50` | 테스트할 descriptor 개수 (쉼표 구분) |
| `--descriptor-mode` | `sequential` | Descriptor 선택 방식 |
| `--models` | (전체) | 학습할 모델 목록 (쉼표 구분) |
| `--test-size` | `0.2` | Hold-out 테스트셋 비율 |
| `--cv-folds` | `5` | K-Fold 교차검증 폴드 수 |
| `--random-seed` | `42` | 랜덤 시드 |
| `--regularization` | `False` | 강한 정규화 적용 (소규모 데이터용) |
| `--no-plots` | `False` | 그래프 생성 건너뛰기 |

### 4.5 지원 모델 (8개)

| 모델 | 설명 |
|------|------|
| `RandomForest` | Random Forest Regressor |
| `ExtraTrees` | Extra Trees Regressor |
| `XGBoost` | XGBoost Regressor (설치 필요) |
| `LightGBM` | LightGBM Regressor (설치 필요) |
| `Ridge` | Ridge Regression |
| `Lasso` | Lasso Regression |
| `ElasticNet` | ElasticNet Regression |
| `GPR` | Gaussian Process Regressor |

```bash
# 특정 모델만 학습
cdml train --input data.parquet --models "XGBoost,RandomForest,Ridge"
```

### 4.6 출력 시각화

ML 학습 완료 후 다음 플롯들이 자동 생성됩니다:

| 파일명 | 설명 |
|--------|------|
| `pred_vs_actual.png` | 예측값 vs 실제값 산점도 |
| `residual_analysis.png` | 잔차 분석 (분포 및 패턴) |
| `feature_importance.png` | Top 15 Feature Importance |
| `model_comparison.png` | 모델별 성능 비교 차트 |
| `all_models_comparison.png` | 전체 모델 Pred vs Actual 비교 |
| `test_prediction_comparison.png` | 테스트셋 샘플별 예측 비교 |

---

## 5. 고급 사용법

### 5.1 개별 전처리 단계

```bash
# 1. PubChem XML → Parquet 변환
cdml preprocess xml-to-parquet \
    --input compounds.xml.gz \
    --output molecules.parquet \
    --filter-property "Molecular Weight" \
    --filter-max 500

# 2. Descriptor 스키마 생성
cdml preprocess generate-schema \
    --input data_dir/ \
    --output schema.json \
    --quick

# 3. Descriptor 계산
cdml preprocess calculate-descriptors \
    --input molecules.parquet \
    --output descriptors/ \
    --schema schema.json \
    --timeout 60
```

### 5.2 대규모 데이터 처리

```bash
# 파일당 샘플링 (메모리 절약)
cdml run \
    --parquet-glob "large_data/*.parquet" \
    --output-dir results/ \
    --sample-per-file 10000

# 체크포인트 활성화 (중단 후 재시작 가능)
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/
    # 기본적으로 체크포인트 활성화됨

# 체크포인트 비활성화
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir results/ \
    --no-checkpoint
```

### 5.3 GPU 설정

```bash
# 특정 GPU 사용
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --gpu-id 1

# CPU 강제 사용
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --cpu
```

---

## 6. 출력 파일 설명

### 6.1 Track 1 출력

| 파일명 | 설명 |
|--------|------|
| `pass1_statistics.csv` | Pass 1 통계 정보 (분산, 결측치 등) |
| `cluster_info.json` | Spearman 클러스터 정보 |
| `filtering_summary.json` | 전체 필터링 요약 |
| `final_descriptors.txt` | 최종 선택된 descriptor 목록 |

### 6.2 Track 2 출력

| 파일명 | 설명 |
|--------|------|
| `ml_results.json` | 전체 실험 결과 (모든 모델) |
| `model_comparison.csv` | 모델별 성능 비교표 |
| `best_model.json` | 최고 성능 모델 정보 |
| `pred_vs_actual.png` | 예측값 vs 실제값 플롯 |
| `residual_analysis.png` | 잔차 분석 플롯 |
| `feature_importance.png` | Feature Importance 플롯 |
| `model_comparison.png` | 모델 비교 차트 |
| `all_models_comparison.png` | 전체 모델 비교 플롯 |
| `test_prediction_comparison.png` | 테스트셋 예측 비교 플롯 |

---

## 7. 실행 예시: 전체 워크플로우

### 7.1 예시 데이터셋 정보

`reference/` 폴더에 있는 예시 데이터로 전체 워크플로우를 실행한 결과입니다.

| 파일 | 샘플 수 | 설명 |
|------|---------|------|
| `train_samples_61.csv` | 61 | Track 2 학습 데이터 (863개 descriptor 포함) |
| `test_samples_16.csv` | 16 | Track 2 테스트 데이터 (외부 검증용) |

### 7.2 Track 1: Descriptor 필터링

```bash
# 필터링 파이프라인 실행
cdml run \
    --parquet-glob "data/*.parquet" \
    --output-dir output/track1 \
    --variance-threshold 0.01 \
    --max-missing-ratio 0.30 \
    --spearman-threshold 0.75 \
    --vif-threshold 10.0 \
    --cpu
```

**Track 1 결과 (`reference/example_output/track1/`):**

| 단계 | 입력 | 출력 | 설명 |
|------|------|------|------|
| Pass 1 | 863 descriptors | 803 | 분산/결측치 필터링 |
| Pass 2 | 803 descriptors | 215 clusters | Spearman 상관 클러스터링 |
| Pass 3 | 215 representatives | 39 | VIF 다중공선성 필터링 |

**출력 파일:**
```
reference/example_output/track1/
├── pass1_statistics.csv      # 863개 descriptor 통계
├── cluster_info.json         # 215개 클러스터 정보
├── filtering_summary.json    # 필터링 요약
└── final_descriptors.txt     # 최종 39개 descriptor
```

### 7.3 Track 2: ML 모델 학습 (Random Seed Search)

Track 1에서 클러스터링된 descriptor들 중에서 Random Seed Search를 통해 최적의 조합을 탐색합니다.

```bash
# ML 학습 (별도 테스트셋 사용)
cdml train \
    --input reference/train_samples_61.csv \
    --test-input reference/test_samples_16.csv \
    --target-col pLeach \
    --output-dir output/track2 \
    --descriptor-sizes 30,35,40 \
    --descriptor-mode random_alternative \
    --random-seed 4897
```

**Random Seed Search 결과:**

5,000개의 random seed를 탐색하여 최적의 35개 descriptor 조합을 발견했습니다.

| Seed | R² | 비고 |
|------|-----|------|
| 10 | 0.2792 | 초기 |
| 331 | 0.5230 | 개선 |
| 811 | 0.6247 | 개선 |
| 3399 | 0.6941 | 개선 |
| **4897** | **0.7527** | **최종 Best** |

### 7.4 Track 2 결과: 8개 모델 앙상블 비교

**전체 모델 성능 비교 (`reference/example_output/track2/model_comparison.csv`):**

| Rank | Model | CV R² | Test R² | RMSE |
|------|-------|-------|---------|------|
| 1 | **XGBoost** | -0.56 ± 0.87 | **0.7527** | 1.31 |
| 2 | RandomForest | -0.25 ± 0.46 | 0.5798 | 1.71 |
| 3 | LightGBM | -0.17 ± 0.21 | 0.2153 | 2.34 |
| 4 | ExtraTrees | -0.17 ± 0.31 | 0.0607 | 2.56 |
| 5 | GPR | -0.07 ± 0.07 | -0.1157 | 2.79 |
| 6 | Lasso | -0.99 ± 0.65 | -4.91 | 6.43 |
| 7 | ElasticNet | -0.88 ± 0.67 | -5.36 | 6.67 |
| 8 | Ridge | -1.19 ± 0.75 | -9.77 | 8.68 |

**Best Model: XGBoost (35 Descriptors)**
- Test R²: **0.7527**
- Test RMSE: 1.31
- Test MAE: 1.11

### 7.5 Top 15 Feature Importance

| Rank | Descriptor | Importance |
|------|------------|------------|
| 1 | ATSC8are | 11.22% |
| 2 | GATS4i | 7.82% |
| 3 | MATS3are | 7.81% |
| 4 | AATSC5i | 7.21% |
| 5 | ATSC3c | 6.65% |
| 6 | MATS1i | 6.18% |
| 7 | nHBAcc | 4.95% |
| 8 | Sse | 4.91% |
| 9 | MPC3 | 4.38% |
| 10 | BIC5 | 4.17% |

### 7.6 출력 폴더 구조

```
reference/example_output/
├── track1/                           # Track 1 결과
│   ├── pass1_statistics.csv          # 863개 descriptor 통계
│   ├── cluster_info.json             # 215개 클러스터 정보
│   ├── filtering_summary.json        # 필터링 요약
│   └── final_descriptors.txt         # 최종 39개 descriptor
│
└── track2/                           # Track 2 결과
    ├── ml_results.json               # 전체 모델 실험 결과
    ├── model_comparison.csv          # 8개 모델 성능 비교
    ├── pred_vs_actual.png            # 예측 vs 실제 플롯
    ├── residual_analysis.png         # 잔차 분석 플롯
    ├── feature_importance.png        # Feature Importance 플롯
    ├── model_comparison.png          # 모델 비교 차트
    ├── all_models_comparison.png     # 전체 모델 비교 (2x4 grid)
    └── test_prediction_comparison.png # 테스트셋 예측 비교
```

---

## 8. 문제 해결

### 8.1 일반적인 오류

**오류: "No descriptors remaining after Pass1"**
```bash
# 해결: 최소 유효 샘플 수 감소
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --min-effective-n 30
```

**오류: GPU 메모리 부족**
```bash
# 해결: CPU 모드 사용 또는 샘플링
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --cpu
# 또는
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --sample-per-file 5000
```

**오류: "XGBoost/LightGBM not found"**
```bash
# 해결: 패키지 설치
pip install xgboost lightgbm
```

### 8.2 성능 최적화

1. **GPU 사용**: 가능한 경우 GPU 모드 사용 (기본)
2. **샘플링**: 대규모 데이터는 `--sample-per-file` 사용
3. **병렬 처리**: 여러 파일은 자동 병렬 처리됨

### 8.3 로그 확인

```bash
# 상세 로그 출력
cdml run --parquet-glob "data/*.parquet" --output-dir results/ --verbose
```

---

## 부록: 빠른 시작 예제

```bash
# 1. 설치
pip install -r requirements.txt
pip install -e .
pip install xgboost lightgbm  # 선택

# 2. Track 2: ML 학습 (예제 데이터)
cdml train \
    --input reference/train_samples_61.csv \
    --test-input reference/test_samples_16.csv \
    --target-col pLeach \
    --output-dir output/track2 \
    --descriptor-sizes 30,35,40 \
    --descriptor-mode sequential

# 3. 결과 확인
cat output/track2/model_comparison.csv
```
